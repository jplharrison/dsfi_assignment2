---
title: "DSFI_A2"
---

# Introduction

The State of the Nation Address (SONA) serves as an annual narrative roadmap of South Africa, highlighting its triumphs, challenges, and future trajectories. Delivered by the President, this address not only provides a summary of the nation's current status but also sets the tone for governmental strategies, policies, and priorities for the coming year. The addresses serve as a snapshot into South Africa's challenges, successes and socioeconomic state at a given time. Hence analysis of the sentiment and topics of the speeches can provide a framework for a deeper understanding of trends and topics from presidents' rhetoric less clouded by the bias of political analysts. 

In the era of data science, where Natural Language Processing(NLP) has become a potent tool to extract meaningful patterns from large volumes of textual data, it is of profound interest to apply such methods to SONA speeches. By employing advanced techniques such as sentiment analysis and topic modelling, one can unearth the latent themes dominating these addresses over three decades and gauge the sentiment fluctuations accompanying them. This presents a data-driven perspective on South Africa's political discourse,

The following proceeds XXX first sections. Firstly a literature review will be conducted on the existing sentiment analysis and topic modelling methods available and used in academia and industry. Thereafter a preliminary exploration of the data occurs to understand the structure and potential trends in the data prior to modelling applications. The Methods section will then detail the sentiment analysis, topic modelling and metrics used in these models. The results of the paper are briefly presented and interpreted before we discuss the overall trends and findings of the paper. We conclude by surmising the findings of the paper, highlighting limitations and presenting avenues for future research into SONA NLP work. 





```{python}
pip install transformers
```

```{python}
#| include: false
# General imports
import pickle
from joblib import dump, load
import os
import pandas as pd
import re
import numpy as np
import string

# NLTK imports
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Visualization imports
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud, STOPWORDS

# Preprocessing imports
from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS, TfidfVectorizer
from sklearn.preprocessing import LabelEncoder

# Model selection imports
from sklearn.model_selection import train_test_split, GridSearchCV

# Machine learning model imports
from sklearn.svm import SVC
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from catboost import Pool, cv, CatBoostClassifier

# Word embedding imports
from gensim.models import Word2Vec

# LDA model imports
from gensim.models import LdaModel
from gensim import corpora
import pyLDAvis.gensim_models as gensimvis
import pyLDAvis

# Metrics import
from sklearn.metrics import classification_report, accuracy_score
```


```{python}
#| echo: false
#| eval: false
#| include: false
folder_path = 'speeches'  
files = os.listdir(folder_path)
files = sorted([file for file in files if os.path.isfile(os.path.join(folder_path, file)) and file.endswith('.txt')])

president_names = []

pattern = r'_(.+?)\.txt'  
for file in files:
    match = re.search(pattern, file)
    if match:
        president_name = match.group(1)
        # Remove the "_2" suffix from the president names here
        cleaned_president_name = president_name.replace('_2', '')
        president_names.append(cleaned_president_name)
    else:
        print(f"Warning: No match found in filename: {file}")
        president_names.append('Unknown')  # Placeholder for missing names

# Check  lengths
if len(files) != len(president_names):
    print(f"Warning: Number of files ({len(files)}) does not match number of president names ({len(president_names)})")

def preprocess_speeches(speech):
    # Tokenize the text
    tokens = word_tokenize(speech)
    # Remove punctuation and convert to lowercase
    tokens = [token.lower() for token in tokens if token not in string.punctuation]
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words]
    # Lemmatize tokens
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(token) for token in tokens]
    for i in range(len(tokens)):
        clean_token = ''.join(char for char in tokens[i] if char.isalpha())
        tokens[i] = clean_token
    tokens = [token for token in tokens if len(token)>2]
    return tokens


df = pd.DataFrame(columns=['Presidents', 'Sentences'])
tokenised_speeches = pd.DataFrame(columns=['Presidents', 'Tokens'])  # To store the speeches tokenized by word

# Iterate over all files and extract sentence
for file_index in range(len(files)):
    file_path = os.path.join(folder_path, files[file_index])
    with open(file_path, 'r', encoding='utf-8') as file:
        speech = file.read()    
        tokens = preprocess_speeches(speech)

        lines = file.readlines()[2:] 

    text = ' '.join(lines)
    sentences = sent_tokenize(text)
    cleaned_sentences = [sentence.replace('\n', '') for sentence in sentences]

    current_president = president_names[file_index]
    dftemp = pd.DataFrame({'Presidents': [current_president] * len(cleaned_sentences), 'Sentences': cleaned_sentences})
    dftemp2 = pd.DataFrame({'Presidents': [current_president] * len(tokens), 'Tokens': tokens})
    df = pd.concat([df, dftemp], axis=0, ignore_index=True)
    tokenised_speeches = pd.concat([tokenised_speeches, dftemp2], axis=0, ignore_index=True)

df.reset_index(drop=True, inplace=True)
tokenised_speeches.reset_index(drop=True, inplace=True)
tokenised_speeches = tokenised_speeches[~tokenised_speeches['Tokens'].str.contains(r'[0-9]', na=False)]  ## Remove numeric tokens


# Save the DataFrame to a CSV file
#df.to_csv('finalSentences2.csv', index=False)
#tokenised_speeches.to_csv('finalTokens.csv', index=False)

```


```{python}
a2data = pd.read_csv("finalSentences2.csv")
a2tokens = pd.read_csv("finalTokens.csv")
```


# Methods

## Sentiment Analysis
### Hugging Face 1 

For sentiment analysis, we also employed a model belonging to hugging face called "twitter-roberta-base-sentiment-latest" and "". The architecture for these models is largely the same, but "" differs in that it was trained primarily on political tweets, which is lesser in the training data size but potentially more domain relevant to the task at hand. 

 This is a transformer-based transfer learning approach. Essentially this means that the model has been pretrained on data to learn how to assign sentiment scores then the trained model is used to extract sentiment scores for our dataset. The model used is more specifically considered a time language model. The time Language Models (LM) foundation is anchored on the RoBERTa architecture, which is a refined variant of BERT (Bidirectional Encoder Representations from Transformers). One of the standout characteristics of RoBERTa is its bidirectional context processing. Unlike conventional models, RoBERTa reviews words in relation to their entire surrounding context, absorbing nuances from both the preceding and following parts of the text. 

Moreover, RoBERTa adopts a Transformer architecture, known for its self-attention mechanism. This mechanism empowers RoBERTa to assign varying importance levels to distinct words in a sentence, ensuring it recognizes and processes dependencies irrespective of their dispersion within the body of text.

Key to its training process is  RoBERTa's utilization of masked language modelling. Here, select words in a sentence are intermittently substituted with a [MASK] token. The model is then tasked with deducing the original word, relying solely on the surrounding context. This method is important in refining RoBERTa's grasp of language semantics.

Differentiating from its predecessor, BERT, RoBERTa's pretraining process has been further optimized. It undergoes training on a more expansive dataset of 10 years of Twitter data. Another differentiating factor from BERT is how RoBERTa dispenses with the next sentence prediction task, a staple in BERT, and recalibrates the masking strategy to elevate its efficiency. The RoBERTa model for a given body of text returns a class probability value of -1 for negative sentiment, 0 for neutral and 1 for positive the highest probability over the three classes is the assigned sentiment. We multiply the class values by their probabilities and sum them to gain a sentiment score between -1 and 1 and use this coupled with the assigned sentiment class for our model evaluation. 

link: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest?text=ayo


## Topic Modelling 
### Latent Dirichlet Allocation

Latent Dirichlet Allocation (LDA) is a probabilitistic model which was implemented as a topic modelling technique to extract meaningful latent topics from the SONA corpus. The SONA speeches are pre-processed to remove stop words, punctuation, and other textual debris. The documents are then lemmatised and tokenised into word-tokens. These tokens are used to create a document-term matrix that contains the frequency of words in each document. The Gensim library was used to enable the training of LDA models on the preprocessed data, and facilitated the extraction of topics associated with their respective word distributions. The resulting topics were then visualized using the pyLDAvis package, to create a interpretable overview of the extracted topics. This process was first performed using a corpus containing all thirty-six speeches. The initial model had five topics, and the number of topics was iteratively decreased until the topics differentiated nicely across the latent variables. This number of topics (3) was then used to train a model for each president's individual corpus of speeches. 

### Probablistic Latent Semantic Analysis

Probablistic Latent Semantic Analysis (pLSA) is the second topic modelling technique used to extract latent topics from the corpus of documents. The text data is preprocessed similarly to LDA; removing stop words, punctuation, and debris, followed by lemmatisation and tokenisation, and then the creation of a document-term matrix. After the pre-processing is complete, pLSA begins by initialising random probabilities for topics and words within topics. The topic and word probabilties are then iteratively updated using the Expectation Maximisation (EM) algorithm. Once the algorithm reaches convergence, there is a resulting set of topics, each containing a set of words. The Gensim package was used to implement the training of the pLSA models, and the matplotlib package was used to visualise the results.

## Results and Discussion

### Latent Dirichlet Allocation

The ALL models were trained on the corpus of all thirty-six speeches, iteratively decreasing the number of topics from five until three. At five topics, two of the topics are almost overlaid - indicating that they are closely linked and probably contain a single topic. At four topics, one of the topics sits almost on the origin of the latent variables. This suggests that this 'topic' does not have differentiating features and likely consists of neutral words, for example it contains 'new', 'also', and a set of numbers, 'one', 'two', 'million'. The third model, with three topics, has three clearly differentiated topics sitting at the extremes of the latent variables axes. Three-topics models were then trained for each of the presidents, using only their respective speeches as the corpus. We gave the top ten words from each topic for each presidents' model and for the three-topic ALL model to ChatGPT to see if it could discern the nature of the topics identified by the LDA models. The output is as follows:  

LDA-Ramaphosa:

+ Topic 1: People and societal needs - this topic includes words related to the needs of the people and society. This could be associated with President Ramaphosa's focus on addressing the needs of the South African population, which could include policies related to social welfare and community development. 
    + Examples: "people," "need," "african".
+ Topic 2: Economic development and business - President Ramaphosa is known for promoting economic development and business growth in South Africa. This topic contains words related to business and economic sectors. 
    + Examples: "business," "government," "economic".
+ Topic 3: Time and work commitment - this topic contains words related to time and work commitment, possibly reflecting President Ramaphosa's commitment to his role and responsibilities as a leader. 
    + Examples: "year," "work," "must".

LDA-Zuma:

+ Topic 1: South Africa and government - this topic includes words related to South Africa and government. President Zuma's tenure was marked by various political and governmental issues, making this a prominent topic.
    + Examples: "south," "government," "africa"
+ Topic 2: Economic sectors and development - President Zuma's administration likely involved policies and discussions related to economic sectors and development, as indicated by the words in this topic.
    + Examples: "sector," "new," "economic"
+ Topic 3: Time and population - this topic may be associated with President Zuma's time in office and concerns related to the South African population.
    + Examples: "year," "country," "million"

LDA-Mandela:

+ Topic 1: Public affairs and the country - this topic encompasses words associated with public affairs and the country. Given Nelson Mandela's role as South Africa's first post-apartheid president, it's likely that topics related to the nation were significant.
    + Examples: "public," "country," "african"
+ Topic 2: Government work and public service - President Mandela's government focused on public service and the work required to build a new South Africa.
    + Examples: "government," "work," "service"
+ Topic 3: Time and commitment - Words related to time and commitment reflect Mandela's dedication to the country and his work.
    + Example: "year," "must," "national"

LDA-deKlerk:

+ Topic 1: Political alliance and elections - this topic includes words related to political alliances and elections. President de Klerk played a crucial role in the transition from apartheid to democracy.
    + Examples: "alliance," "election," "african"
+ Topic 2: Constitution and political parties - given his role in the negotiation of South Africa's new constitution, this topic reflects words related to the constitution and political parties.
    + Examples: "constitution," "party," "power"
+ Topic 3: South African provinces and constitutional concerns - the words in this topic may relate to the various provinces in South Africa and constitutional concerns that were addressed during his leadership.
    + Examples: "south," "province," "constitutional"

LDA-Mbeki:

+ Topic 1: Time and government programs - this topic could be associated with President Mbeki's focus on time-bound government programs and initiatives.
    + Examples: "year," "programme," "government"
+ Topic 2: National issues and the country - this topic encompasses words related to national issues and the country, reflecting his leadership during a period of significant national importance.
    + Examples: "country," "national," "work"
+ Topic 3: Economic sectors and government efforts - President Mbeki's administration focused on economic sectors and government efforts, as indicated by the words in this topic.
    + Examples: "sector," "effort," "government"

LDA-Motlanthe:
+ Topic 1 - South Africa and African development - this topic includes words related to South Africa and African development, reflecting a focus on regional and national development.
    + Examples: "south," "african," "development"
+ Topic 2: Government work and public sector - this topic likely represents the emphasis on government work and the public sector during President Motlanthe's leadership.
    + Examples: "government," "sector," "regard"
+ Topic 3: Economic development and work - words related to economic development and work suggest a focus on economic policies and employment during his tenure.
    + Examples: "economic," "work," "growth"

LDA-All:

+ Topic 1: South Africa and African development - this topic emphasizes South Africa and its development, which is a broad, overarching theme applicable to all six Presidents.
    + Examples: "south," "africa," "new"
+ Topic 2: People, work, and service - this topic encompasses words related to the people, their work, and the services provided, reflecting the importance of public service and commitment.
    + Examples: "people," "work," "service"
Topic 3 - Time and government - the words in this topic are related to time, government, and national affairs, indicating a focus on governance and the passage of time across all Presidential terms.
    + Examples: "year," "african," "government"

### Probablistic Latent Semantic Analysis

pLSA models are very sensitive to data sparsity, the document-term matrix has only around a third of its cells populated. The model struggles to capture meaningful relationships through its dimensionality reduction techniques in the sparse data.


```{python}
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig
import numpy as np
from scipy.special import softmax


```


```{python}
#| echo: false
#| eval: false
#| include: false
data = a2data

import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig

# Assuming a2data is loaded
data = a2data

# Define the preprocess function
def preprocess(text):
    new_text = []
    for t in text.split(" "):
        t = '@user' if t.startswith('@') and len(t) > 1 else t
        t = 'http' if t.startswith('http') else t
        new_text.append(t)
    return " ".join(new_text)

# Define the model details
MODEL = "cardiffnlp/twitter-roberta-base-sentiment-latest"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
config = AutoConfig.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

# Preprocess the sentences
data['Preprocessed_Sentences'] = data['Sentences'].apply(preprocess)

# Compute the weighted sentiment score and get the model's sentiment classification
def compute_sentiment_data(text):
    # Tokenize and get model output
    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)
    output = model(**encoded_input)
    scores = output[0][0].detach().numpy()
    probabilities = softmax(scores)
    
    # Compute the weighted sentiment score
    sentiment_values = np.array([-1, 0, 1])  # Corresponding to Negative, Neutral, and Positive
    sentiment_score = np.dot(sentiment_values, probabilities)
    
    # Get the model's sentiment classification
    ranking = np.argsort(scores)
    ranking = ranking[::-1]
    label = config.id2label[ranking[0]]
    
    return sentiment_score, label

# Predict sentiment data for the preprocessed sentences
sentiment_data = data['Preprocessed_Sentences'].apply(compute_sentiment_data)
data['Sentiment_Score'] = [s[0] for s in sentiment_data]
data['Predicted_Label'] = [s[1] for s in sentiment_data]

# Save the results
data.to_csv("HFM1_SentimentData.csv")

data.head()

```



```{python}
HFM1 = pd.read_csv("HFM1_SentimentData.csv")
presidents_order = ['Mandela', 'deKlerk', 'Mbeki', ' Motlanthe', 'Zuma', 'Ramaphosa']
mean_scores_per_president = HFM1.groupby('Presidents')['Sentiment_Score'].mean()
adjusted_presidents_order = ['deKlerk'] + [president for president in presidents_order if president != 'deKlerk']
mean_scores_reordered = mean_scores_per_president.reindex(adjusted_presidents_order)

# Plotting the reordered mean sentiment scores
#plt.figure(figsize=(12, 7))
mean_scores_reordered.plot(kind='bar', color='skyblue')
plt.title('Mean Sentiment Scores per President')
plt.xlabel('President')
plt.ylabel('Mean Sentiment Score')
plt.axhline(0, color='red', linestyle='--')  #line at y=0 for reference
plt.tight_layout()
plt.show()
```


```{python}
colors = {'negative': '#FF9999', 'neutral': '#99CCFF', 'positive': '#99FF99'}
sentiment_counts = HFM1.groupby('Presidents')['Predicted_Label'].value_counts(normalize=True).unstack().fillna(0)

sentiment_counts.reindex(adjusted_presidents_order).plot(kind='bar', stacked=True, color=[colors[col] for col in sentiment_counts.columns])
plt.title('Sentiment Distribution per President')
plt.ylabel('Percentage')
plt.xlabel('President')
plt.legend(title='Sentiment')
plt.tight_layout()
plt.show()
```


```{python}
from matplotlib.colors import LinearSegmentedColormap
from matplotlib import cm
from matplotlib import cm

def plot_for_president_gradient(president, df):
    # Filter dataframe for the selected president
    president_df = df[df['Presidents'] == president]
    
    # Sorting data by order (using the 'Unnamed: 0' column as the order)
    president_df = president_df.sort_values(by='Unnamed: 0')
    
    # Normalize the scores to [0,1] for colormap
    norm = plt.Normalize(-1, 1)
    
    # Custom colormap: Red -> Gray -> Blue
    custom_cmap = LinearSegmentedColormap.from_list("custom", ["red", "gray", "blue"])
    
    # Plotting with a black background and custom colormap
    fig, ax = plt.subplots()
    bars = ax.bar(np.arange(len(president_df)), president_df['Sentiment_Score'], 
                  color=custom_cmap(norm(president_df['Sentiment_Score'])), width=1.0)
    
    ax.set_title(f'Sentiment Score over time for President {president}')
    ax.set_xlabel('Order of Sentences')
    ax.set_ylabel('Sentiment Intensity')
    ax.axhline(0, color='white',linewidth=0.5)
    ax.grid(axis='y', color='white', linestyle='--', linewidth=0.5)
    ax.set_facecolor('black')
    fig.colorbar(cm.ScalarMappable(norm=norm, cmap=custom_cmap), ax=ax, label='Sentiment Score')
    
    plt.show()

```


```{python}
presidents_list = HFM1['Presidents'].unique()
def plot_in_grid(president, ax):
    """Plot sentiment scores for a given president on a given axes."""
    president_df = HFM1[HFM1['Presidents'] == president]
    president_df = president_df.sort_values(by='Unnamed: 0')
    
    # Normalize the scores for colormap
    norm = plt.Normalize(-1, 1)
    custom_cmap = LinearSegmentedColormap.from_list("custom", ["red", "gray", "blue"])

    bars = ax.bar(np.arange(len(president_df)), president_df['Sentiment_Score'], 
                  color=custom_cmap(norm(president_df['Sentiment_Score'])), width=1.0)
    ax.set_title(f'{president}')
    ax.axhline(0, color='white', linewidth=0.5)
    ax.grid(axis='y', color='white', linestyle='--', linewidth=0.5)
    ax.set_facecolor('black')

# Creating a 2x3 grid plot for all presidents
fig, axes = plt.subplots(2, 3)
fig.suptitle('Sentiment Scores over time for each President', fontsize=16)

for president, ax in zip(adjusted_presidents_order, axes.ravel()):
    plot_in_grid(president, ax)

# Adjust layout
plt.tight_layout()
plt.subplots_adjust(top=0.90)
plt.show()
```



```{python}
pastel_colors = ['#FFB3BA', '#FFDFBA', '#FFFFBA', '#BAFFC9', '#BAE1FF', '#D9BAFF']

def plot_histogram(president, color, ax):
    """Plot histogram of sentiment scores for a given president on a given axes."""
    president_df = HFM1[HFM1['Presidents'] == president]
    ax.hist(president_df['Sentiment_Score'], bins=30, color=color, edgecolor='white')
    ax.set_title(f'{president}')
    ax.set_xlabel('Sentiment Score')
    ax.set_ylabel('Frequency')
    ax.grid(axis='y', linestyle='--', linewidth=0.5)

# Creating a 2x3 grid plot for histograms of all presidents
fig, axes = plt.subplots(2, 3)
fig.suptitle('Distribution of Sentiment Scores for each President', fontsize=16)

for president, color, ax in zip(adjusted_presidents_order, pastel_colors, axes.ravel()):
    plot_histogram(president, color, ax)

# Adjust layout
plt.tight_layout()
plt.subplots_adjust(top=0.90)
plt.show()
```

```{python, eval=F}
a2tokens = pd.read_csv("finalTokens.csv")
tokens = [text.split() for text in a2tokens["Tokens"]]

# Create a dictionary and corpus
dct = corpora.Dictionary(tokens)
corpus = [dct.doc2bow(t) for t in tokens]

# Train the LDA models
m_lda_3 = LdaModel(corpus=corpus, num_topics=3, id2word=dct, passes=20)
m_lda_4 = LdaModel(corpus=corpus, num_topics=4, id2word=dct, passes=20)
m_lda_5 = LdaModel(corpus=corpus, num_topics=5, id2word=dct, passes=20)


# Print the topics and associated words
topics = m_lda.print_topics(num_words=10)
for topic in topics:
    print(topic)

# Prepare the visualization
vis3 = gensimvis.prepare(m_lda_3, corpus, dct)
vis4 = gensimvis.prepare(m_lda_4, corpus, dct)
vis5 = gensimvis.prepare(m_lda_5, corpus, dct)

# Save model and visualisation objects
# pyLDAvis.save_html(vis3, "lda_3topic_vis.html")
# m_lda_3.save("m_lda_3")
# pyLDAvis.save_html(vis4, "lda_4topic_vis.html")
# m_lda_4.save("m_lda_4")
# pyLDAvis.save_html(vis5, "lda_5topic_vis.html")
# m_lda_5.save("m_lda")

```


```{python}

m_lda_3 = LdaModel.load("topic_models/m_lda_3")
m_lda_4 = LdaModel.load("topic_models/m_lda_4")
m_lda_5 = LdaModel.load("topic_models/m_lda")

def extract_topics(lda_model, m):
    df=pd.DataFrame({})
    topics = lda_model.print_topics(num_words=10)
    for i, topic in enumerate(topics):
        heading = i+1
        content = topic[1]
        items = content.split(' + ')
        tmp_df = pd.DataFrame({f'M{m} Topic {heading}': [item.strip().replace('"', '').replace('*', ' | ') for item in items]})
        df = pd.concat([df,tmp_df],axis=1)
    return df

topics_df = pd.concat([extract_topics(m_lda_3, 3),extract_topics(m_lda_4, 4),extract_topics(m_lda_5, 5)], axis=1)

md_tbl = topics_df.to_markdown(index=False)
md_tbl

```
