---
title: "DSFI_A2"
---

# Introduction

The State of the Nation Address (SONA) serves as an annual narrative roadmap of South Africa, highlighting its triumphs, challenges, and future trajectories. Delivered by the President, this address not only provides a summary of the nation's current status but also sets the tone for governmental strategies, policies, and priorities for the coming year. The addresses serve as a snapshot into South Africa's challenges, successes and socioeconomic state at a given time. Hence analysis of the sentiment and topics of the speeches can provide a framework for a deeper understanding of trends and topics from presidents' rhetoric less clouded by the bias of political analysts. 

In the era of data science, where Natural Language Processing(NLP) has become a potent tool to extract meaningful patterns from large volumes of textual data, it is of profound interest to apply such methods to SONA speeches. By employing advanced techniques such as sentiment analysis and topic modelling, one can unearth the latent themes dominating these addresses over three decades and gauge the sentiment fluctuations accompanying them. This presents a data-driven perspective on South Africa's political discourse,

The following proceeds XXX first sections. Firstly a literature review will be conducted on the existing sentiment analysis and topic modelling methods available and used in academia and industry. Thereafter a preliminary exploration of the data occurs to understand the structure and potential trends in the data prior to modelling applications. The Methods section will then detail the sentiment analysis, topic modelling and metrics used in these models. The results of the paper are briefly presented and interpreted before we discuss the overall trends and findings of the paper. We conclude by surmising the findings of the paper, highlighting limitations and presenting avenues for future research into SONA NLP work. 


# Literature Review

## Sentiment Analysis

Sentiment Analysis is a prominent field within the broader scope of NLP techniques, and it has gained significant attention in scientific research in recent years. Sentiment classification, specifically polarity estimation, is amongst the most extensively studied tasks of sentiment analysis. Polarity is often categorized as either positive or negative, but a third category labeled as "neutral" can be introduced (Wang et al., 2014). This is what our sentiment analysis will focus on. 

There are two primary approaches to sentiment analysis, the machine learning and lexicon-based approaches. 

The other primary approach to sentiment analysis is the lexicon-based approach. This approach analyzes each word in a document and gives it a score, on a scale where one side is completely negative, and the other is completely positive, with neutral in the middle. For example, words that would get a negative rating include, “ugly”,  while a positively rated word is “good”(Ligthart et al., 2021). (Vinodhini 2012) notes that lexicons are heavily reliant on the domain, due to the type of language used in different fields. This is why adjusting the lexicon to the target domain is needed, however can be very time consuming.

Two popular lexicons are AFINN and NRC. 
AFINN gives words a rating between -5 and 5, with -5 meaning a very negative word while 5 indicates that the word is very positive (Al-Shabi, 2020). The lexicon was created by Finn Arup Nielsen. The NRC Emotion Lexicon (Mohammad & Turney, 2010) on the other hand focuses on emotional words only, and provides a list of 13,872 terms in several categories. Specifically, the terms are classified as “negative”, “positive”, and then based on (Plutchik, 1980), words have corresponding can have associated emotions: “anger”, “disgust”, “fear”, “sadness”, “joy” , “anticipation”, “trust”, and “surprise”. These are the two lexicons we will be using in this paper.

Machine learning approaches for sentiment analysis tasks are divided into three categories: unsupervised learning, semi-supervised learning, and supervised learning. Unsupervised learning methods cluster unlabeled data into groups that exhibit similarity (Li and Liu 2014). Semi-supervised learning makes use of both labeled and unlabelled data in the training process (da Silva et al. 2016a, b), and can lead to good model performance while less human work is required compared to supervised learning. Supervised learning, which is the most human-intensive, occurs when a model is trained on fully labeled data. This can often result in the optimal model performance, however due to the requirement of labeled data it can lead to inefficiencies (Hemmatian and Sohrabi 2017).

According to (Yadav and Vishwakarma, 2019) who reviewed over 100 papers which used deep learning (subset of machine learning) techniques to perform sentiment analysis, the most common deep learning models are RNNs, CNNs, and LSTMs, with the latter providing the best performance. They also said that utilizing machine learning approaches to conduct sentiment analysis was a promising field, while noting that the dataset needs to be large enough for a respectable analysis to take place, which is a challenge.

Furthermore, (Loureiro et al., 2022) showed the importance of Time language models, which are a set of language models which undergo continual learning on, in this case, tweets. (Loureiro et al., 2022) shows that this approach enhances the models ability to deal with out-of-distribution inputs, as well enhances competitiveness with standard benchmark tests. They’re also seen to deal well with the problem of concept drift. Since our data is over a long period of time, we will be using these time language models too.



```{python}
pip install transformers
```

```{python}
#| include: false
# General imports
import pickle
from joblib import dump, load
import os
import pandas as pd
import re
import numpy as np
import string

# NLTK imports
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Visualization imports
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud, STOPWORDS

# Preprocessing imports
from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS, TfidfVectorizer
from sklearn.preprocessing import LabelEncoder

# Model selection imports
from sklearn.model_selection import train_test_split, GridSearchCV

# Machine learning model imports
from sklearn.svm import SVC
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from catboost import Pool, cv, CatBoostClassifier

# Word embedding imports
from gensim.models import Word2Vec

# LDA model imports
from gensim.models import LdaModel
from gensim import corpora
import pyLDAvis.gensim_models as gensimvis
import pyLDAvis

# Metrics import
from sklearn.metrics import classification_report, accuracy_score
```


```{python}
#| echo: false
#| eval: false
#| include: false
folder_path = 'speeches'  
files = os.listdir(folder_path)
files = sorted([file for file in files if os.path.isfile(os.path.join(folder_path, file)) and file.endswith('.txt')])

president_names = []

pattern = r'_(.+?)\.txt'  
for file in files:
    match = re.search(pattern, file)
    if match:
        president_name = match.group(1)
        # Remove the "_2" suffix from the president names here
        cleaned_president_name = president_name.replace('_2', '')
        president_names.append(cleaned_president_name)
    else:
        print(f"Warning: No match found in filename: {file}")
        president_names.append('Unknown')  # Placeholder for missing names

# Check  lengths
if len(files) != len(president_names):
    print(f"Warning: Number of files ({len(files)}) does not match number of president names ({len(president_names)})")

def preprocess_speeches(speech):
    # Tokenize the text
    tokens = word_tokenize(speech)
    # Remove punctuation and convert to lowercase
    tokens = [token.lower() for token in tokens if token not in string.punctuation]
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words]
    # Lemmatize tokens
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(token) for token in tokens]
    for i in range(len(tokens)):
        clean_token = ''.join(char for char in tokens[i] if char.isalpha())
        tokens[i] = clean_token
    tokens = [token for token in tokens if len(token)>2]
    return tokens


df = pd.DataFrame(columns=['Presidents', 'Sentences'])
tokenised_speeches = pd.DataFrame(columns=['Presidents', 'Tokens'])  # To store the speeches tokenized by word

# Iterate over all files and extract sentence
for file_index in range(len(files)):
    file_path = os.path.join(folder_path, files[file_index])
    with open(file_path, 'r', encoding='utf-8') as file:
        speech = file.read()    
        tokens = preprocess_speeches(speech)

        lines = file.readlines()[2:] 

    text = ' '.join(lines)
    sentences = sent_tokenize(text)
    cleaned_sentences = [sentence.replace('\n', '') for sentence in sentences]

    current_president = president_names[file_index]
    dftemp = pd.DataFrame({'Presidents': [current_president] * len(cleaned_sentences), 'Sentences': cleaned_sentences})
    dftemp2 = pd.DataFrame({'Presidents': [current_president] * len(tokens), 'Tokens': tokens})
    df = pd.concat([df, dftemp], axis=0, ignore_index=True)
    tokenised_speeches = pd.concat([tokenised_speeches, dftemp2], axis=0, ignore_index=True)

df.reset_index(drop=True, inplace=True)
tokenised_speeches.reset_index(drop=True, inplace=True)
tokenised_speeches = tokenised_speeches[~tokenised_speeches['Tokens'].str.contains(r'[0-9]', na=False)]  ## Remove numeric tokens


# Save the DataFrame to a CSV file
#df.to_csv('finalSentences2.csv', index=False)
#tokenised_speeches.to_csv('finalTokens.csv', index=False)

```


```{python}
a2data = pd.read_csv("finalSentences2.csv")
a2tokens = pd.read_csv("finalTokens.csv")
```


# Methods
## Sentiment Analysis

### AFINN

The AFINN lexicon is a valuable resource consisting of a vast list of English words, with each word meticulously assigned a sentiment score. These scores span a numerical range from -5 to 5, encompassing the spectrum of sentiments present in the English language. Negative sentiment is represented by scores in the negative range, where more negative scores signify a greater intensity of negative emotion associated with the word. Conversely, positive sentiment is conveyed through positive scores, with the magnitude of the positive number indicating the degree of positivity linked to the word. Words with a neutral sentiment receive a score of 0, indicating their emotional neutrality.

In practice, the sentiment analysis process unfolds by systematically evaluating the words within each sentence in the dataset. For each word in a sentence, its associated sentiment score is extracted from the AFINN lexicon. Subsequently, the sentiment scores for all the words in a sentence are summed to compute the overall sentiment of that sentence. This method, in turn, facilitates the categorization of sentences by the president delivering them. The collective sentiment analysis allows for a comprehensive examination of the language employed and the emotional disposition of each president, thereby providing valuable insights into the emotional nuances that characterize their speeches.

### NRC lexicon

The NRC lexicon is a comprehensive linguistic resource that encompasses a substantial collection of English words. Each word in this lexicon is associated with specific emotional and sentiment categories, such as joy, sadness, anger, trust, and fear, among others. These categories offer a more detailed perspective on the emotions of South African presidents compared to other lexicons. Words are tagged with binary values indicating whether they evoke a particular emotion or sentiment, making it possible to identify not only the polarity of the sentiment (positive or negative) but also the specific emotional dimension.

This is conducted by once again analysing each sentence in the dataset and selecting the emotion associated with each word within a sentence based on the NRC lexicon. By assigning these emotional labels to individual words, a more comprehensive and fine-grained understanding of sentiment and emotion within text is achieved. The collective emotional and sentiment labels for words in a sentence are then aggregated over all sentences to compute the overall sentiment and emotional composition of each president. This grouping by president allows for an in-depth exploration of the specific emotional and sentimental patterns and variations exhibited by each president in their speeches. This approach thus offers the positivity/negativity metric offered by the AFINN lexicon, but also decomposes these broad categories into specific emotions.

### Hugging Face 1 

For sentiment analysis, we also employed a model belonging to hugging face called "twitter-roberta-base-sentiment-latest" and "". The architecture for these models is largely the same, but "" differs in that it was trained primarily on political tweets, which is lesser in the training data size but potentially more domain relevant to the task at hand. 

 This is a transformer-based transfer learning approach. Essentially this means that the model has been pretrained on data to learn how to assign sentiment scores then the trained model is used to extract sentiment scores for our dataset. The model used is more specifically considered a time language model. The time Language Models (LM) foundation is anchored on the RoBERTa architecture, which is a refined variant of BERT (Bidirectional Encoder Representations from Transformers). One of the standout characteristics of RoBERTa is its bidirectional context processing. Unlike conventional models, RoBERTa reviews words in relation to their entire surrounding context, absorbing nuances from both the preceding and following parts of the text. 

Moreover, RoBERTa adopts a Transformer architecture, known for its self-attention mechanism. This mechanism empowers RoBERTa to assign varying importance levels to distinct words in a sentence, ensuring it recognizes and processes dependencies irrespective of their dispersion within the body of text.

Key to its training process is  RoBERTa's utilization of masked language modelling. Here, select words in a sentence are intermittently substituted with a [MASK] token. The model is then tasked with deducing the original word, relying solely on the surrounding context. This method is important in refining RoBERTa's grasp of language semantics.

Differentiating from its predecessor, BERT, RoBERTa's pretraining process has been further optimized. It undergoes training on a more expansive dataset of 10 years of Twitter data. Another differentiating factor from BERT is how RoBERTa dispenses with the next sentence prediction task, a staple in BERT, and recalibrates the masking strategy to elevate its efficiency. The RoBERTa model for a given body of text returns a class probability value of -1 for negative sentiment, 0 for neutral and 1 for positive the highest probability over the three classes is the assigned sentiment. We multiply the class values by their probabilities and sum them to gain a sentiment score between -1 and 1 and use this coupled with the assigned sentiment class for our model evaluation. 

link: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest?text=ayo
```{python}
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig
import numpy as np
from scipy.special import softmax


```


```{python}
#| echo: false
#| eval: false
#| include: false
data = a2data

import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig

# Assuming a2data is loaded
data = a2data

# Define the preprocess function
def preprocess(text):
    new_text = []
    for t in text.split(" "):
        t = '@user' if t.startswith('@') and len(t) > 1 else t
        t = 'http' if t.startswith('http') else t
        new_text.append(t)
    return " ".join(new_text)

# Define the model details
MODEL = "cardiffnlp/twitter-roberta-base-sentiment-latest"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
config = AutoConfig.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

# Preprocess the sentences
data['Preprocessed_Sentences'] = data['Sentences'].apply(preprocess)

# Compute the weighted sentiment score and get the model's sentiment classification
def compute_sentiment_data(text):
    # Tokenize and get model output
    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)
    output = model(**encoded_input)
    scores = output[0][0].detach().numpy()
    probabilities = softmax(scores)
    
    # Compute the weighted sentiment score
    sentiment_values = np.array([-1, 0, 1])  # Corresponding to Negative, Neutral, and Positive
    sentiment_score = np.dot(sentiment_values, probabilities)
    
    # Get the model's sentiment classification
    ranking = np.argsort(scores)
    ranking = ranking[::-1]
    label = config.id2label[ranking[0]]
    
    return sentiment_score, label

# Predict sentiment data for the preprocessed sentences
sentiment_data = data['Preprocessed_Sentences'].apply(compute_sentiment_data)
data['Sentiment_Score'] = [s[0] for s in sentiment_data]
data['Predicted_Label'] = [s[1] for s in sentiment_data]

# Save the results
data.to_csv("HFM1_SentimentData.csv")

data.head()

```



```{python}
HFM1 = pd.read_csv("HFM1_SentimentData.csv")
presidents_order = ['Mandela', 'deKlerk', 'Mbeki', ' Motlanthe', 'Zuma', 'Ramaphosa']
mean_scores_per_president = HFM1.groupby('Presidents')['Sentiment_Score'].mean()
adjusted_presidents_order = ['deKlerk'] + [president for president in presidents_order if president != 'deKlerk']
mean_scores_reordered = mean_scores_per_president.reindex(adjusted_presidents_order)

# Plotting the reordered mean sentiment scores
#plt.figure(figsize=(12, 7))
mean_scores_reordered.plot(kind='bar', color='skyblue')
plt.title('Mean Sentiment Scores per President')
plt.xlabel('President')
plt.ylabel('Mean Sentiment Score')
plt.axhline(0, color='red', linestyle='--')  #line at y=0 for reference
plt.tight_layout()
plt.show()
```


```{python}
colors = {'negative': '#FF9999', 'neutral': '#99CCFF', 'positive': '#99FF99'}
sentiment_counts = HFM1.groupby('Presidents')['Predicted_Label'].value_counts(normalize=True).unstack().fillna(0)

sentiment_counts.reindex(adjusted_presidents_order).plot(kind='bar', stacked=True, color=[colors[col] for col in sentiment_counts.columns])
plt.title('Sentiment Distribution per President')
plt.ylabel('Percentage')
plt.xlabel('President')
plt.legend(title='Sentiment')
plt.tight_layout()
plt.show()
```


```{python}
from matplotlib.colors import LinearSegmentedColormap
from matplotlib import cm
from matplotlib import cm

def plot_for_president_gradient(president, df):
    # Filter dataframe for the selected president
    president_df = df[df['Presidents'] == president]
    
    # Sorting data by order (using the 'Unnamed: 0' column as the order)
    president_df = president_df.sort_values(by='Unnamed: 0')
    
    # Normalize the scores to [0,1] for colormap
    norm = plt.Normalize(-1, 1)
    
    # Custom colormap: Red -> Gray -> Blue
    custom_cmap = LinearSegmentedColormap.from_list("custom", ["red", "gray", "blue"])
    
    # Plotting with a black background and custom colormap
    fig, ax = plt.subplots()
    bars = ax.bar(np.arange(len(president_df)), president_df['Sentiment_Score'], 
                  color=custom_cmap(norm(president_df['Sentiment_Score'])), width=1.0)
    
    ax.set_title(f'Sentiment Score over time for President {president}')
    ax.set_xlabel('Order of Sentences')
    ax.set_ylabel('Sentiment Intensity')
    ax.axhline(0, color='white',linewidth=0.5)
    ax.grid(axis='y', color='white', linestyle='--', linewidth=0.5)
    ax.set_facecolor('black')
    fig.colorbar(cm.ScalarMappable(norm=norm, cmap=custom_cmap), ax=ax, label='Sentiment Score')
    
    plt.show()

```


```{python}
presidents_list = HFM1['Presidents'].unique()
def plot_in_grid(president, ax):
    """Plot sentiment scores for a given president on a given axes."""
    president_df = HFM1[HFM1['Presidents'] == president]
    president_df = president_df.sort_values(by='Unnamed: 0')
    
    # Normalize the scores for colormap
    norm = plt.Normalize(-1, 1)
    custom_cmap = LinearSegmentedColormap.from_list("custom", ["red", "gray", "blue"])

    bars = ax.bar(np.arange(len(president_df)), president_df['Sentiment_Score'], 
                  color=custom_cmap(norm(president_df['Sentiment_Score'])), width=1.0)
    ax.set_title(f'{president}')
    ax.axhline(0, color='white', linewidth=0.5)
    ax.grid(axis='y', color='white', linestyle='--', linewidth=0.5)
    ax.set_facecolor('black')

# Creating a 2x3 grid plot for all presidents
fig, axes = plt.subplots(2, 3)
fig.suptitle('Sentiment Scores over time for each President', fontsize=16)

for president, ax in zip(adjusted_presidents_order, axes.ravel()):
    plot_in_grid(president, ax)

# Adjust layout
plt.tight_layout()
plt.subplots_adjust(top=0.90)
plt.show()
```



```{python}
pastel_colors = ['#FFB3BA', '#FFDFBA', '#FFFFBA', '#BAFFC9', '#BAE1FF', '#D9BAFF']

def plot_histogram(president, color, ax):
    """Plot histogram of sentiment scores for a given president on a given axes."""
    president_df = HFM1[HFM1['Presidents'] == president]
    ax.hist(president_df['Sentiment_Score'], bins=30, color=color, edgecolor='white')
    ax.set_title(f'{president}')
    ax.set_xlabel('Sentiment Score')
    ax.set_ylabel('Frequency')
    ax.grid(axis='y', linestyle='--', linewidth=0.5)

# Creating a 2x3 grid plot for histograms of all presidents
fig, axes = plt.subplots(2, 3)
fig.suptitle('Distribution of Sentiment Scores for each President', fontsize=16)

for president, color, ax in zip(adjusted_presidents_order, pastel_colors, axes.ravel()):
    plot_histogram(president, color, ax)

# Adjust layout
plt.tight_layout()
plt.subplots_adjust(top=0.90)
plt.show()
```

<<<<<<< HEAD
### Hugging Face 2


```{python}
# Assuming a2data is loaded
data = a2data

# Define the preprocess function
def preprocess(text):
    new_text = []
    for t in text.split(" "):
        t = '@user' if t.startswith('@') and len(t) > 1 else t
        t = 'http' if t.startswith('http') else t
        new_text.append(t)
    return " ".join(new_text)

# Define the model details
MODEL = "cardiffnlp/xlm-twitter-politics-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
config = AutoConfig.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

# Preprocess the sentences
data['Preprocessed_Sentences'] = data['Sentences'].apply(preprocess)

# Compute the weighted sentiment score and get the model's sentiment classification
def compute_sentiment_data(text):
    # Tokenize and get model output
    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)
    output = model(**encoded_input)
    scores = output[0][0].detach().numpy()
    probabilities = softmax(scores)
    
    # Compute the weighted sentiment score
    sentiment_values = np.array([-1, 0, 1])  # Corresponding to Negative, Neutral, and Positive
    sentiment_score = np.dot(sentiment_values, probabilities)
    
    # Get the model's sentiment classification
    ranking = np.argsort(scores)
    ranking = ranking[::-1]
    label = config.id2label[ranking[0]]
    
    return sentiment_score, label

# Predict sentiment data for the preprocessed sentences
sentiment_data = data['Preprocessed_Sentences'].apply(compute_sentiment_data)
data['Sentiment_Score'] = [s[0] for s in sentiment_data]
data['Predicted_Label'] = [s[1] for s in sentiment_data]

# Save the results
data.to_csv("HFM2_SentimentData.csv")

data.head()
```
=======
```{python, eval=F}
a2tokens = pd.read_csv("dsfi_assignment2/finalTokens.csv")
tokens = [text.split() for text in a2tokens["Tokens"]]

# Create a dictionary and corpus
dct = corpora.Dictionary(tokens)
corpus = [dct.doc2bow(t) for t in tokens]

# Train the LDA models
 m_lda_3 = LdaModel(corpus=corpus, num_topics=3, id2word=dct, passes=20)
 m_lda_4 = LdaModel(corpus=corpus, num_topics=4, id2word=dct, passes=20)
 m_lda_5 = LdaModel(corpus=corpus, num_topics=5, id2word=dct, passes=20)


# Print the topics and associated words
 topics = m_lda.print_topics(num_words=10)
 for topic in topics:
     print(topic)

# Prepare the visualization
 vis3 = gensimvis.prepare(m_lda_3, corpus, dct)
 vis4 = gensimvis.prepare(m_lda_4, corpus, dct)
 vis5 = gensimvis.prepare(m_lda_5, corpus, dct)

# Save model and visualisation objects
# pyLDAvis.save_html(vis3, "lda_3topic_vis.html")
# m_lda_3.save("m_lda_3")
# pyLDAvis.save_html(vis4, "lda_4topic_vis.html")
# m_lda_4.save("m_lda_4")
# pyLDAvis.save_html(vis5, "lda_5topic_vis.html")
# m_lda_5.save("m_lda")

```


```{python}

m_lda_3 = LdaModel.load("m_lda_3")
m_lda_4 = LdaModel.load("m_lda_4")
m_lda_5 = LdaModel.load("m_lda")

def extract_topics(lda_model, m):
    df=pd.DataFrame({})
    topics = lda_model.print_topics(num_words=10)
    for i, topic in enumerate(topics):
        heading = i+1
        content = topic[1]
        items = content.split(' + ')
        tmp_df = pd.DataFrame({f'M{m} Topic {heading}': [item.strip().replace('"', '').replace('*', ' | ') for item in items]})
        df = pd.concat([df,tmp_df],axis=1)
    return df

topics_df = pd.concat([extract_topics(m_lda_3, 3),extract_topics(m_lda_4, 4),extract_topics(m_lda_5, 5)], axis=1)

md_tbl = topics_df.to_markdown(index=False)
md_tbl

```
>>>>>>> 00f4f43a946c8792968a1d42838db7c1e0087281

# Results

```{python}
#| echo: false
#| eval: false
#| include: false


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from sklearn.preprocessing import StandardScaler
from afinn import Afinn
 
#instantiate afinn
afn = Afinn()
data = pd.read_csv("finalSentences2.csv")

# compute scores (polarity) and labels
scores = [afn.score(sentence) for sentence in data["Sentences"]]
sentiment = ['positive' if score > 0
						else 'negative' if score < 0
							else 'neutral'
								for score in scores]
	
# dataframe creation
afn_df = pd.DataFrame()
afn_df['Presidents'] = data['Presidents']
afn_df['Sentences'] = data['Sentences']
afn_df['scores'] = scores
afn_df['sentiments'] = sentiment

# scaler = StandardScaler()
# scaled_data = scaler.fit_transform(afn_df['scores'].values.reshape(-1,1))
# afn_df['scores'] = scaled_data.squeeze()

presidents_order = ['Mandela', 'deKlerk', 'Mbeki', ' Motlanthe', 'Zuma', 'Ramaphosa']
mean_scores_per_president = afn_df.groupby('Presidents')['scores'].mean()
adjusted_presidents_order = ['deKlerk'] + [president for president in presidents_order if president != 'deKlerk']
mean_scores_reordered = mean_scores_per_president.reindex(adjusted_presidents_order)

# Plotting the reordered mean sentiment scores
plt.figure(figsize=(12, 7))
mean_scores_reordered.plot(kind='bar', color='skyblue')
plt.title('Mean Sentiment Scores per President')

plt.title("Mean Sentiment Scores per President", fontsize=20)
plt.xlabel('President', fontsize=20)
plt.ylabel('Mean Sentiment Score', fontsize=20)
plt.xticks(rotation=45, fontsize=16)
plt.yticks(fontsize=16)  # Set the font size for y-axis tick labels
plt.tight_layout()
plt.show()
```

The mean sentiment scores per president show President Mbeki exhibiting the highest mean sentiment score at approximately 1.65, suggesting a generally positive sentiment in his speeches. President Motlanthe followed closely with a mean sentiment score of approximately 1.44, indicating a similar trend of positively oriented speeches. In contrast, President de Klerk presented the lowest mean sentiment score, around 0.67, while Presidents Ramaphosa and Zuma demonstrated mean sentiment scores around 0.95 and 0.92, respectively.


```{python}
#| echo: false
from PIL import Image
import matplotlib.pyplot as plt

# Open the PNG image
image = Image.open("wes_appendix/sent_mean.png")

# Display the image using Matplotlib
plt.imshow(image)
plt.axis('off')  # Turn off axis labels and ticks
plt.show()
```

```{python}
#| echo: false
#| eval: false
#| include: false
colors = {'negative': '#FF9999', 'neutral': '#99CCFF', 'positive': '#99FF99'}
sentiment_counts = afn_df.groupby('Presidents')['sentiments'].value_counts(normalize=True).unstack().fillna(0)

sentiment_counts.reindex(adjusted_presidents_order).plot(kind='bar', stacked=True, figsize=(12,7), color=[colors[col] for col in sentiment_counts.columns])
plt.title('Sentiment Distribution per President', fontsize=20)
plt.ylabel('Percentage', fontsize=20)
plt.xlabel('President', fontsize=20)
plt.legend(title='Sentiment', fontsize=20, title_fontsize=20)
plt.tight_layout()
plt.xticks(rotation=45, fontsize=16)
plt.yticks(fontsize=16) 
plt.show()
```

The barplot below shows the 

```{python}
#| echo: false
from PIL import Image
import matplotlib.pyplot as plt

# Open the PNG image
image = Image.open("wes_appendix/sent_percentage.png")

# Display the image using Matplotlib
plt.imshow(image)
plt.axis('off')  # Turn off axis labels and ticks
plt.show()
```

Sentiment over time for each president.

```{python}
#| echo: false
#| eval: false
#| include: false

from matplotlib.colors import LinearSegmentedColormap
from matplotlib import cm
from matplotlib import cm

def plot_for_president_gradient(president, df):
    # Filter dataframe for the selected president
    president_df = df[df['Presidents'] == president]
    
    # Sorting data by order (using the 'Unnamed: 0' column as the order)
    president_df = president_df.sort_values(by='Unnamed: 0')
    
    # Normalize the scores to [0,1] for colormap
    norm = plt.Normalize(-1, 1)
    
    # Custom colormap: Red -> Gray -> Blue
    custom_cmap = LinearSegmentedColormap.from_list("custom", ["red", "gray", "blue"])
    
    # Plotting with a black background and custom colormap
    fig, ax = plt.subplots(figsize=(10, 5))
    bars = ax.bar(np.arange(len(president_df)), president_df['Sentiment_Score'], 
                  color=custom_cmap(norm(president_df['Sentiment_Score'])), width=1.0)
    
    ax.set_title(f'Sentiment Score over time for President {president}')
    ax.set_xlabel('Order of Sentences')
    ax.set_ylabel('Sentiment Intensity')
    ax.axhline(0, color='white',linewidth=0.5)
    ax.grid(axis='y', color='white', linestyle='--', linewidth=0.5)
    ax.set_facecolor('black')
    fig.colorbar(cm.ScalarMappable(norm=norm, cmap=custom_cmap), ax=ax, label='Sentiment Score')
    
    plt.show()


presidents_list = afn_df['Presidents'].unique()
def plot_in_grid(president, ax):
    """Plot sentiment scores for a given president on a given axes."""
    president_df = afn_df[afn_df['Presidents'] == president]
    #president_df = president_df.sort_values(by='Unnamed: 0')
    
    # Normalize the scores for colormap
    norm = plt.Normalize(-1, 1)
    custom_cmap = LinearSegmentedColormap.from_list("custom", ["red", "gray", "blue"])

    bars = ax.bar(np.arange(len(president_df)), president_df['scores'], 
                  color=custom_cmap(norm(president_df['scores'])), width=1.0)
    ax.set_title(f'{president}', fontsize=20)
    ax.axhline(0, color='white', linewidth=0.5)
    ax.grid(axis='y', color='white', linestyle='--', linewidth=0.5)
    ax.set_facecolor('black')

# Creating a 2x3 grid plot for all presidents
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
fig.suptitle('Sentiment Scores over time for each President', fontsize=20)

for president, ax in zip(adjusted_presidents_order, axes.ravel()):
    plot_in_grid(president, ax)

# Adjust layout
plt.tight_layout()
plt.subplots_adjust(top=0.90)

for ax in axes.ravel():
    ax.tick_params(axis='x', labelrotation=45, labelsize=16)
    ax.tick_params(axis='y', labelsize=16)

# Set x and y labels fontsize
for ax in axes[1, :]:
    ax.set_xlabel('Sentences', fontsize=20)
for ax in axes[:, 0]:
    ax.set_ylabel('Scores', fontsize=20)

plt.show()
```

```{python}
#| echo: false

from PIL import Image
import matplotlib.pyplot as plt

# Open the PNG image
image = Image.open("wes_appendix/sent_over_time.png")

# Display the image using Matplotlib
plt.imshow(image)
plt.axis('off')  # Turn off axis labels and ticks
plt.show()
```



The histograms below show the sentiment score distribution for the presidents. All histograms appear to be slightly skewed to the left, indicating a high frequency of positive sentiment. Mandela appears to have the most evenly spread sentiment distribution, with the fewest number of protruding bars, while de Klerk mainly has a uniform sentiment distribution, with a notable deviation from that occuring in the neutral sentiment territory. Ramaphosa's, Mbeki's and Zuma's sentiment distributions are both centered on the positive side of zero, indicating a generally positive sentiment, while Motlanthe's most common sentiment is actually slightly negative, however that is offset by the high frequency of positive sentiments.

```{python}
#| echo: false
#| eval: false
#| include: false
pastel_colors = ['#FFB3BA', '#FFDFBA', '#FFFFBA', '#BAFFC9', '#BAE1FF', '#D9BAFF']

def plot_histogram(president, color, ax):
    """Plot histogram of sentiment scores for a given president on a given axes."""
    president_df = afn_df[afn_df['Presidents'] == president]
    
    x_range = max(president_df['scores']) - min(president_df['scores'])
    half_x_range = x_range / 2
    
    # Set the x-axis limits to center the histogram around 0
    ax.set_xlim(-10, 10)

    ax.hist(president_df['scores'], bins=30, color=color, edgecolor='white')
    ax.set_title(f'{president}', fontsize=20)
    ax.set_xlabel('Sentiment Score', fontsize=20)
    ax.set_ylabel('Frequency', fontsize=20)
    ax.tick_params(axis='x', labelsize=16)
    ax.tick_params(axis='y', labelsize=16)
    ax.grid(axis='y', linestyle='--', linewidth=0.5)

# Creating a 2x3 grid plot for histograms of all presidents
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
fig.suptitle('Distribution of Sentiment Scores for each President', fontsize=20)

for president, color, ax in zip(adjusted_presidents_order, pastel_colors, axes.ravel()):
    plot_histogram(president, color, ax)

# Adjust layout
plt.tight_layout()
plt.subplots_adjust(top=0.90)
plt.show()

```

```{python}
#| echo: false

from PIL import Image
import matplotlib.pyplot as plt

# Open the PNG image
image = Image.open("wes_appendix/sent_histograms.png")

# Display the image using Matplotlib
plt.imshow(image)
plt.axis('off')  # Turn off axis labels and ticks
plt.show()
```

### NRC

```{python}
#| echo: false
#| eval: false
#| include: false
import pandas as pd
from nrclex import NRCLex

# Function to find the top emotions for a text
def find_top_emotions(text):
    emotion = NRCLex(text)
    return emotion.top_emotions

# Apply the function to each row in the DataFrame
data['Top_Emotions'] = data['Sentences'].apply(find_top_emotions)

unique_emotion_columns = ['fear', 'anger', 'anticipation','anticip', 'trust', 'surprise', 'positive', 'negative', 'sadness', 'disgust', 'joy']
presidents = data['Presidents'].unique()

president_dataframes = {president: pd.DataFrame(0, columns=unique_emotion_columns, index=[0]) for president in presidents}

for index, row in data.iterrows():
    president = row['Presidents']
    emotions = dict(row['Top_Emotions'])
    #president_df = president_dataframes[president]
    
    # Iterate through unique_emotion_columns
    for emotion_column in emotions.keys():
        if emotion_column in emotions:
            value = emotions[emotion_column]
            president_dataframes[president][emotion_column] += value

president_dataframes['Mandela']

for pres in presidents:
    president_dataframes[pres] = president_dataframes[pres].div(president_dataframes[pres].sum(axis=1), axis=0)

for president, df in president_dataframes.items():
    if 'anticipation' in df.columns and 'anticip' in df.columns:
        df['anticipation'] += df['anticip']  # Add 'anticip' to 'anticipation'
        df.drop(columns=['anticip'], inplace=True)  # Remove 'anticip' column

pastel_colors = ['#FFB3BA', '#FFDFBA', '#FFFFBA', '#BAFFC9', '#BAE1FF', '#D9BAFF']
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
fig.suptitle('Distribution of Sentiment Scores for each President', fontsize=20)

order = ['deKlerk','Mandela', 'Mbeki', ' Motlanthe', 'Zuma', 'Ramaphosa']

for president, ax, colour in zip(order, axes.ravel(), pastel_colors):
    data = president_dataframes[president]
    x = list(data.keys())
    x.remove('positive')
    x.remove('negative')
    y = data[x].values.squeeze()
    ax.set_ylim(0, 0.25)
    ax.bar(x, y, color=colour)
    ax.set_title(president, fontsize=20)
    # ax.set_xlabel('Sentiment Category', fontsize=16)
    ax.set_ylabel('Sentiment Score', fontsize=16)
    ax.tick_params(axis='x', labelrotation=45, labelsize=16)
    ax.tick_params(axis='y', labelsize=16)

# Adjust layout
plt.tight_layout()
plt.subplots_adjust(top=0.90)
plt.show()
```

Using the NRC emotion lexicon we see that all presidents have their most common sentiment being positive, while the particular emotions in there sentences differ. A common emotion amongst all presidents is trust. Anticipation is a frequently evoked emotion from the presidents, besides for deKlerk. Other relatively common emotions include fear and joy.

```{python}
#| echo: false

from PIL import Image
import matplotlib.pyplot as plt

image = Image.open("wes_appendix/emotion_scores.png")
# Display the image using Matplotlib
plt.imshow(image)
plt.axis('off')  # Turn off axis labels and ticks
plt.show()
```