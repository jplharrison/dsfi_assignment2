<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>DSFI_A2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">DSFI_A2</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Appendix.html" rel="" target="">
 <span class="menu-text">Appendix</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#literature-review" id="toc-literature-review" class="nav-link" data-scroll-target="#literature-review">Literature Review</a>
  <ul class="collapse">
  <li><a href="#sentiment-analysis" id="toc-sentiment-analysis" class="nav-link" data-scroll-target="#sentiment-analysis">Sentiment Analysis</a></li>
  <li><a href="#topic-modelling" id="toc-topic-modelling" class="nav-link" data-scroll-target="#topic-modelling">Topic Modelling</a></li>
  </ul></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">Methods</a>
  <ul class="collapse">
  <li><a href="#sentiment-analysis-1" id="toc-sentiment-analysis-1" class="nav-link" data-scroll-target="#sentiment-analysis-1">Sentiment Analysis</a>
  <ul class="collapse">
  <li><a href="#afinn" id="toc-afinn" class="nav-link" data-scroll-target="#afinn">AFINN</a></li>
  <li><a href="#nrc-lexicon" id="toc-nrc-lexicon" class="nav-link" data-scroll-target="#nrc-lexicon">NRC lexicon</a></li>
  <li><a href="#roberta-transfer-learning" id="toc-roberta-transfer-learning" class="nav-link" data-scroll-target="#roberta-transfer-learning">RoBERTa Transfer Learning</a></li>
  </ul></li>
  <li><a href="#topic-modelling-1" id="toc-topic-modelling-1" class="nav-link" data-scroll-target="#topic-modelling-1">Topic Modelling</a>
  <ul class="collapse">
  <li><a href="#latent-dirichlet-allocation" id="toc-latent-dirichlet-allocation" class="nav-link" data-scroll-target="#latent-dirichlet-allocation">Latent Dirichlet Allocation</a></li>
  <li><a href="#probablistic-latent-semantic-analysis" id="toc-probablistic-latent-semantic-analysis" class="nav-link" data-scroll-target="#probablistic-latent-semantic-analysis">Probablistic Latent Semantic Analysis</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a>
  <ul class="collapse">
  <li><a href="#data-exploration" id="toc-data-exploration" class="nav-link" data-scroll-target="#data-exploration">Data Exploration</a></li>
  <li><a href="#roberta" id="toc-roberta" class="nav-link" data-scroll-target="#roberta">RoBERTa</a></li>
  <li><a href="#roberta-domain-specific" id="toc-roberta-domain-specific" class="nav-link" data-scroll-target="#roberta-domain-specific">RoBERTa: Domain Specific</a>
  <ul class="collapse">
  <li><a href="#nrc" id="toc-nrc" class="nav-link" data-scroll-target="#nrc">NRC</a></li>
  </ul></li>
  <li><a href="#latent-dirichlet-allocation-1" id="toc-latent-dirichlet-allocation-1" class="nav-link" data-scroll-target="#latent-dirichlet-allocation-1">Latent Dirichlet Allocation</a>
  <ul class="collapse">
  <li><a href="#probablistic-latent-semantic-analysis-1" id="toc-probablistic-latent-semantic-analysis-1" class="nav-link" data-scroll-target="#probablistic-latent-semantic-analysis-1">Probablistic Latent Semantic Analysis</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#limitations-and-recommendations" id="toc-limitations-and-recommendations" class="nav-link" data-scroll-target="#limitations-and-recommendations">Limitations and Recommendations</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">DSFI_A2</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The State of the Nation Address (SONA) serves as an annual narrative roadmap of South Africa, highlighting its triumphs, challenges, and future trajectories. Delivered by the President, this address not only provides a summary of the nation’s current status but also sets the tone for governmental strategies, policies, and priorities for the coming year. The addresses serve as a snapshot into South Africa’s challenges, successes and socioeconomic state at a given time. Hence analysis of the sentiment and topics of the speeches can provide a framework for a deeper understanding of trends and topics from presidents’ rhetoric less clouded by the bias of political analysts.</p>
<p>In the era of data science, where Natural Language Processing(NLP) has become a potent tool to extract meaningful patterns from large volumes of textual data, it is of profound interest to apply such methods to SONA speeches. By employing advanced techniques such as sentiment analysis and topic modelling, one can unearth the latent themes dominating these addresses over three decades and gauge the sentiment fluctuations accompanying them. This presents a data-driven perspective on South Africa’s political discourse.</p>
<p>The following proceeds XXX first sections. Firstly a literature review will be conducted on the existing sentiment analysis and topic modelling methods available and used in academia as well as in industry. Thereafter a preliminary exploration of the data occurs to understand the structure and potential trends in the data prior to modelling applications. The Methods section will then detail the sentiment analysis, topic modelling and metrics used in these models. The results of the paper are then briefly presented and interpreted before we discuss the overall trends and findings of the paper. We conclude by summarising the findings of the paper, highlighting limitations and presenting avenues for future research into SONA NLP work.</p>
</section>
<section id="literature-review" class="level1">
<h1>Literature Review</h1>
<section id="sentiment-analysis" class="level2">
<h2 class="anchored" data-anchor-id="sentiment-analysis">Sentiment Analysis</h2>
<p>Sentiment Analysis is a prominent field within the broader scope of NLP techniques, and it has gained significant attention in scientific research in recent years. Sentiment classification, specifically polarity estimation, is amongst the most extensively studied tasks of sentiment analysis. Polarity is often categorized as either positive or negative, but a third category labeled as “neutral” can be introduced (Wang et al., 2014). This is what our sentiment analysis will focus on.</p>
<p>There are two primary approaches to sentiment analysis, the machine learning and lexicon-based approaches.</p>
<p>The other primary approach to sentiment analysis is the lexicon-based approach. This approach analyzes each word in a document and gives it a score, on a scale where one side is completely negative, and the other is completely positive, with neutral in the middle. For example, words that would get a negative rating include, “ugly”, while a positively rated word is “good”(Ligthart et al., 2021). (Vinodhini 2012) notes that lexicons are heavily reliant on the domain, due to the type of language used in different fields. This is why adjusting the lexicon to the target domain is needed, however can be very time consuming.</p>
<p>Two popular lexicons are AFINN and NRC. AFINN gives words a rating between -5 and 5, with -5 meaning a very negative word while 5 indicates that the word is very positive (Al-Shabi, 2020). The lexicon was created by Finn Arup Nielsen. The NRC Emotion Lexicon (Mohammad &amp; Turney, 2010) on the other hand focuses on emotional words only, and provides a list of 13,872 terms in several categories. Specifically, the terms are classified as “negative”, “positive”, and then based on (Plutchik, 1980), words have corresponding can have associated emotions: “anger”, “disgust”, “fear”, “sadness”, “joy” , “anticipation”, “trust”, and “surprise”. These are the two lexicons we will be using in this paper.</p>
<p>Machine learning approaches for sentiment analysis tasks are divided into three categories: unsupervised learning, semi-supervised learning, and supervised learning. Unsupervised learning methods cluster unlabeled data into groups that exhibit similarity (Li and Liu 2014). Semi-supervised learning makes use of both labeled and unlabelled data in the training process (da Silva et al.&nbsp;2016a, b), and can lead to good model performance while less human work is required compared to supervised learning. Supervised learning, which is the most human-intensive, occurs when a model is trained on fully labeled data. This can often result in the optimal model performance, however due to the requirement of labeled data it can lead to inefficiencies (Hemmatian and Sohrabi 2017).</p>
<p>According to (Yadav and Vishwakarma, 2019) who reviewed over 100 papers which used deep learning (subset of machine learning) techniques to perform sentiment analysis, the most common deep learning models are RNNs, CNNs, and LSTMs, with the latter providing the best performance. They also said that utilizing machine learning approaches to conduct sentiment analysis was a promising field, while noting that the dataset needs to be large enough for a respectable analysis to take place, which is a challenge.</p>
<p>Furthermore, (Loureiro et al., 2022) showed the importance of Time language models, which are a set of language models which undergo continual learning on, in this case, tweets. (Loureiro et al., 2022) shows that this approach enhances the models ability to deal with out-of-distribution inputs, as well enhances competitiveness with standard benchmark tests. They’re also seen to deal well with the problem of concept drift. Since our data is over a long period of time, we will be using these time language models too.</p>
</section>
<section id="topic-modelling" class="level2">
<h2 class="anchored" data-anchor-id="topic-modelling">Topic Modelling</h2>
<p>In the 1980s, topic modelling emerged as a means to enhance the accuracy of information retrieval systems. Deerwester et al (1990) founded one of the earliest topic models known as Latent Semantic Analysis (LSA). LSA groups documents based on latent semantic formations, and makes the assumption that words with similar semantic meanings tend to co-occur. This innovation greatly advanced the capabilities of document retrieval systems because users were no longer required to employ the exact words found in related documents - similarity could be determined through a broader semantic context.</p>
<p>Blei et al.&nbsp;(2003) advanced the techniques implemented in LSA by developing a related modelling algorithm called Latent Dirichlet Allocation (LDA). In LDA, a document is seen as a collection of words drawn from unobserved topics. LDA subsequently assesses the likelihood distribution of a specific word across a range of topics and then the distribution of a specific topic across a collection of documents.</p>
</section>
</section>
<section id="methods" class="level1">
<h1>Methods</h1>
<section id="sentiment-analysis-1" class="level2">
<h2 class="anchored" data-anchor-id="sentiment-analysis-1">Sentiment Analysis</h2>
<section id="afinn" class="level3">
<h3 class="anchored" data-anchor-id="afinn">AFINN</h3>
<p>The AFINN lexicon is a valuable resource consisting of a vast list of English words, with each word meticulously assigned a sentiment score. These scores span a numerical range from -5 to 5, encompassing the spectrum of sentiments present in the English language. Negative sentiment is represented by scores in the negative range, where more negative scores signify a greater intensity of negative emotion associated with the word. Conversely, positive sentiment is conveyed through positive scores, with the magnitude of the positive number indicating the degree of positivity linked to the word. Words with a neutral sentiment receive a score of 0, indicating their emotional neutrality.</p>
<p>In practice, the sentiment analysis process unfolds by systematically evaluating the words within each sentence in the dataset. For each word in a sentence, its associated sentiment score is extracted from the AFINN lexicon. Subsequently, the sentiment scores for all the words in a sentence are summed to compute the overall sentiment of that sentence. This method, in turn, facilitates the categorization of sentences by the president delivering them. The collective sentiment analysis allows for a comprehensive examination of the language employed and the emotional disposition of each president, thereby providing valuable insights into the emotional nuances that characterize their speeches.</p>
</section>
<section id="nrc-lexicon" class="level3">
<h3 class="anchored" data-anchor-id="nrc-lexicon">NRC lexicon</h3>
<p>The NRC lexicon is a comprehensive linguistic resource that encompasses a substantial collection of English words. Each word in this lexicon is associated with specific emotional and sentiment categories, such as joy, sadness, anger, trust, and fear, among others. These categories offer a more detailed perspective on the emotions of South African presidents compared to other lexicons. Words are tagged with binary values indicating whether they evoke a particular emotion or sentiment, making it possible to identify not only the polarity of the sentiment (positive or negative) but also the specific emotional dimension.</p>
<p>This is conducted by once again analysing each sentence in the dataset and selecting the emotion associated with each word within a sentence based on the NRC lexicon. By assigning these emotional labels to individual words, a more comprehensive and fine-grained understanding of sentiment and emotion within text is achieved. The collective emotional and sentiment labels for words in a sentence are then aggregated over all sentences to compute the overall sentiment and emotional composition of each president. This grouping by president allows for an in-depth exploration of the specific emotional and sentimental patterns and variations exhibited by each president in their speeches. This approach thus offers the positivity/negativity metric offered by the AFINN lexicon, but also decomposes these broad categories into specific emotions.</p>
</section>
<section id="roberta-transfer-learning" class="level3">
<h3 class="anchored" data-anchor-id="roberta-transfer-learning">RoBERTa Transfer Learning</h3>
<p>For sentiment analysis, we also employed a model belonging to hugging face called “twitter-roberta-base-sentiment-latest” and ““. The architecture for these models is largely the same, but”” differs in that it was trained primarily on political tweets, which is lesser in the training data size but potentially more domain relevant to the task at hand.</p>
<p>This is a transformer-based transfer learning approach. Essentially this means that the model has been pretrained on data to learn how to assign sentiment scores then the trained model is used to extract sentiment scores for our dataset. The model used is more specifically considered a time language model. The time Language Models (LM) foundation is anchored on the RoBERTa architecture, which is a refined variant of BERT (Bidirectional Encoder Representations from Transformers). One of the standout characteristics of RoBERTa is its bidirectional context processing. Unlike conventional models, RoBERTa reviews words in relation to their entire surrounding context, absorbing nuances from both the preceding and following parts of the text.</p>
<p>Moreover, RoBERTa adopts a Transformer architecture, known for its self-attention mechanism. This mechanism empowers RoBERTa to assign varying importance levels to distinct words in a sentence, ensuring it recognizes and processes dependencies irrespective of their dispersion within the body of text.</p>
<p>Key to its training process is RoBERTa’s utilization of masked language modelling. Here, select words in a sentence are intermittently substituted with a [MASK] token. The model is then tasked with deducing the original word, relying solely on the surrounding context. This method is important in refining RoBERTa’s grasp of language semantics.</p>
<p>Differentiating from its predecessor, BERT, RoBERTa’s pretraining process has been further optimized. It undergoes training on a more expansive dataset of 10 years of Twitter data. Another differentiating factor from BERT is how RoBERTa dispenses with the next sentence prediction task, a staple in BERT, and recalibrates the masking strategy to elevate its efficiency. The RoBERTa model for a given body of text returns a class probability value of -1 for negative sentiment, 0 for neutral and 1 for positive the highest probability over the three classes is the assigned sentiment. We multiply the class values by their probabilities and sum them to gain a sentiment score between -1 and 1 and use this coupled with the assigned sentiment class for our model evaluation.</p>
</section>
</section>
<section id="topic-modelling-1" class="level2">
<h2 class="anchored" data-anchor-id="topic-modelling-1">Topic Modelling</h2>
<section id="latent-dirichlet-allocation" class="level3">
<h3 class="anchored" data-anchor-id="latent-dirichlet-allocation">Latent Dirichlet Allocation</h3>
<p>Latent Dirichlet Allocation (LDA) is a probabilitistic model which was implemented as a topic modelling technique to extract meaningful latent topics from the SONA corpus. The SONA speeches are pre-processed to remove stop words, punctuation, and other textual debris. The documents are then lemmatised and tokenised into word-tokens. These tokens are used to create a document-term matrix that contains the frequency of words in each document. The Gensim library was used to enable the training of LDA models on the preprocessed data, and facilitated the extraction of topics associated with their respective word distributions. The resulting topics were then visualized using the pyLDAvis package, to create a interpretable overview of the extracted topics. This process was first performed using a corpus containing all thirty-six speeches. The initial model had five topics, and the number of topics was iteratively decreased until the topics differentiated nicely across the latent variables. This number of topics (3) was then used to train a model for each president’s individual corpus of speeches.</p>
</section>
<section id="probablistic-latent-semantic-analysis" class="level3">
<h3 class="anchored" data-anchor-id="probablistic-latent-semantic-analysis">Probablistic Latent Semantic Analysis</h3>
<p>Probablistic Latent Semantic Analysis (pLSA) is the second topic modelling technique used to extract latent topics from the corpus of documents. The text data is preprocessed similarly to LDA; removing stop words, punctuation, and debris, followed by lemmatisation and tokenisation, and then the creation of a document-term matrix. After the pre-processing is complete, pLSA begins by initialising random probabilities for topics and words within topics. The topic and word probabilties are then iteratively updated using the Expectation Maximisation (EM) algorithm. Once the algorithm reaches convergence, there is a resulting set of topics, each containing a set of words. The Gensim package was used to implement the training of the pLSA models, and the matplotlib package was used to visualise the results.</p>
</section>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="data-exploration" class="level2">
<h2 class="anchored" data-anchor-id="data-exploration">Data Exploration</h2>
<<<<<<< HEAD
<div class="cell" data-execution_count="10">
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\Wesley King\AppData\Local\Programs\Python\Python311\Lib\site-packages\wordcloud\wordcloud.py:106: MatplotlibDeprecationWarning:

The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.

C:\Users\Wesley King\AppData\Local\Programs\Python\Python311\Lib\site-packages\wordcloud\wordcloud.py:106: MatplotlibDeprecationWarning:

The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.

C:\Users\Wesley King\AppData\Local\Programs\Python\Python311\Lib\site-packages\wordcloud\wordcloud.py:106: MatplotlibDeprecationWarning:

The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.

C:\Users\Wesley King\AppData\Local\Programs\Python\Python311\Lib\site-packages\wordcloud\wordcloud.py:106: MatplotlibDeprecationWarning:

The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.

C:\Users\Wesley King\AppData\Local\Programs\Python\Python311\Lib\site-packages\wordcloud\wordcloud.py:106: MatplotlibDeprecationWarning:

The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.

C:\Users\Wesley King\AppData\Local\Programs\Python\Python311\Lib\site-packages\wordcloud\wordcloud.py:106: MatplotlibDeprecationWarning:
=======
<p>In analyzing the word clouds of various South African presidents in Figure X, there’s a discernible emphasis on governance, nation-building, and the welfare of the South African people. Motlanthe and Mbeki highlighted governmental programs and assured development, while Mandela accentuated societal unity and nation-building. Ramaphosa’s emphasis leaned towards economic investment and support, Zuma prioritized governmental initiatives and societal support, and deKlerk focused on constitutional and governance reforms. Across all presidents, the persistent themes underscore a dedication to governance, the progress of South Africa, and the betterment of its citizens.</p>
<div class="cell" data-execution_count="10">
<div class="cell-output cell-output-stderr">
<pre><code>/opt/anaconda3/envs/firstEnv/lib/python3.10/site-packages/wordcloud/wordcloud.py:106: MatplotlibDeprecationWarning:

The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/anaconda3/envs/firstEnv/lib/python3.10/site-packages/wordcloud/wordcloud.py:106: MatplotlibDeprecationWarning:

The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/anaconda3/envs/firstEnv/lib/python3.10/site-packages/wordcloud/wordcloud.py:106: MatplotlibDeprecationWarning:

The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/anaconda3/envs/firstEnv/lib/python3.10/site-packages/wordcloud/wordcloud.py:106: MatplotlibDeprecationWarning:

The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/anaconda3/envs/firstEnv/lib/python3.10/site-packages/wordcloud/wordcloud.py:106: MatplotlibDeprecationWarning:

The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/anaconda3/envs/firstEnv/lib/python3.10/site-packages/wordcloud/wordcloud.py:106: MatplotlibDeprecationWarning:
>>>>>>> cdd77dcf5cd537e2a21e0be11ffb9a3c9bda83db

The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<<<<<<< HEAD
<p><img src="index_files/figure-html/cell-11-output-2.png" width="1063" height="778" class="figure-img"></p>
<figcaption class="figure-caption">Figure X: Wordcloud per president</figcaption>
=======
<p><img src="index_files/figure-html/cell-11-output-7.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure X: Wordcloud per president</figcaption><p></p>
>>>>>>> cdd77dcf5cd537e2a21e0be11ffb9a3c9bda83db
</figure>
</div>
</div>
</div>
</section>
<section id="roberta" class="level2">
<h2 class="anchored" data-anchor-id="roberta">RoBERTa</h2>
<p>Figure XXX plots the mean sentiment score(-1 to 1, where -1 is perfectly negative, 0 is neutral and 1 is positive) across all presidents where presidents have been ordered by time. Beginning with de Klerk, there is a noticeable negative sentiment. However, as we transition to Mandela’s era, a significant shift occurs, with sentiment becoming predominantly positive. This positive trend not only continues but also amplifies during Mbeki’s tenure.</p>
<p>Following Mbeki, Motlanthe’s sentiment score experiences a slight dip but remains firmly in the positive territory, suggesting his rhetoric, likely inifluenced by the poor economic conditions during this temulruous time in south africas politcs, was less positive than Mbeki’s. The highest peak in positive sentiment is observed during Zuma’s term, which is interesting considering the slide of economic performance during his tenure().This may point to a juxtoposition in his presentation of the stte of the nation and the reality of the peroid both regarding corruption and economic stability() However, it’s noteworthy that Ramaphosa’s sentiment, while still being robustly positive, sees a decline from the high set by Zuma, potentially indicating the effects of rhetoric regarding the COVID-19 pandemic.</p>
<div class="cell" data-execution_count="12">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<<<<<<< HEAD
<p><img src="index_files/figure-html/cell-13-output-1.png" width="662" height="470" class="figure-img"></p>
<figcaption class="figure-caption">Figure X: RoBERTa 1 Mean Sentiment Scores per President</figcaption>
=======
<p><img src="index_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure X: RoBERTa 1 Mean Sentiment Scores per President</figcaption><p></p>
>>>>>>> cdd77dcf5cd537e2a21e0be11ffb9a3c9bda83db
</figure>
</div>
</div>
</div>
<p>In Figure XXX we plot the proportion of each sentiment class across all sentences per president.Mandela and Ramaphosa primarily have positive and neutral sentiments, with Mandela possessing a slightly broader share of positive mentions. De Klerk presents an interesting case; while he has the least proportion of positive sentiments among all the presidents, he also claims the highest negative sentiment. Mbeki and Zuma display an almost balanced distribution between positive and neutral sentiments, with Mbeki tipping slightly more towards the positive end. Motlanthe distinctly stands out, characterized by an overwhelming positive sentiment that far surpasses both the neutral and negative sentiments.</p>
<div class="cell" data-execution_count="13">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<<<<<<< HEAD
<p><img src="index_files/figure-html/cell-14-output-1.png" width="662" height="470" class="figure-img"></p>
<figcaption class="figure-caption">Figure X: RoBERTa 1 Sentiment Distribution per President</figcaption>
=======
<p><img src="index_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure X: RoBERTa 1 Sentiment Distribution per President</figcaption><p></p>
>>>>>>> cdd77dcf5cd537e2a21e0be11ffb9a3c9bda83db
</figure>
</div>
</div>
</div>
<p>To gain a depper understading of the change in sentiment over timie for each given president, and their speeches, we can look to figure XXX in the appendix. While the plot dos provide a granular insight into the variety of sentiment across sentences in presidents’ speaches the lack of discernable trend makes the plot difficult to interpret. Furthermore the sentiment aggregatioin plots at an overall president level provides sufficient insiight. Figure XXX plots the distribution of sentiment scores for each president. For de Klerk, there’s a noticeable tilt towards neutral to negative sentiments. On the other hand, Mandela’s mentions are predominantly positive. Mbeki’s sentiment profile reveals an overwhelmingly positive tone, with more neutrality in tone than Mandela. Motlanthe’s mentions also predominantly exhibit positivity, especially between the 0.50 to 1.00 range. Zuma presents a diverse sentiment spectrum; while there’s a substantial representation in the positive range, especially towards the higher end, there’s also a notable amount neutral sentiment and almost no negative rhetoric. Lastly, discussions about Ramaphosa are mostly tinted with positivity, particularly around the 0.50 to 0.75 range, although some neutral and negative sentiments are present. Overall, while Mandela, Mbeki, Motlanthe, Zuma, and Ramaphosa’s mentions lean more towards positivity, de Klerk’s profile hints at a more neutral with a greater tilt towards negativity.</p>
<div class="cell" data-execution_count="14">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<<<<<<< HEAD
<p><img src="index_files/figure-html/cell-15-output-1.png" width="675" height="457" class="figure-img"></p>
<figcaption class="figure-caption">Figure X: RoBERTa 1 Distribution of Sentiment Scores for each President</figcaption>
=======
<p><img src="index_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure X: RoBERTa 1 Distribution of Sentiment Scores for each President</figcaption><p></p>
>>>>>>> cdd77dcf5cd537e2a21e0be11ffb9a3c9bda83db
</figure>
</div>
</div>
</div>
</section>
<section id="roberta-domain-specific" class="level2">
<h2 class="anchored" data-anchor-id="roberta-domain-specific">RoBERTa: Domain Specific</h2>
<p>In Figure XXX we look at the mean sentiment scorees for each president. The resuls are largely similar as the prior model. De Klerk remains the president with the lowest mean sentiment score while Zuma retainis the highest value. The other preseidents scores while slighly altered still behave similar relative to eachother.</p>
<div class="cell" data-execution_count="16">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<<<<<<< HEAD
<p><img src="index_files/figure-html/cell-17-output-1.png" width="662" height="470" class="figure-img"></p>
<figcaption class="figure-caption">Figure X: RoBERTa 2 Mean Sentiment Scores per President</figcaption>
=======
<p><img src="index_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure X: RoBERTa 2 Mean Sentiment Scores per President</figcaption><p></p>
>>>>>>> cdd77dcf5cd537e2a21e0be11ffb9a3c9bda83db
</figure>
</div>
</div>
</div>
<p>Now looking to the proportion of sentiment classes per president in Figure XXX. We note that de Klerk’s mean sentiment score became more positve we find that the proportioin of negative sentences has remained largely the same rather neutral sentencees in the previous model have now been classified as positve. While the results do look similar there is a clear trend of lesser neutral sentences, possibly speaking to the more domaini specific model’s ability to better discern sentiment of political rhetoric.</p>
<div class="cell" data-execution_count="17">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<<<<<<< HEAD
<p><img src="index_files/figure-html/cell-18-output-1.png" width="662" height="470" class="figure-img"></p>
<figcaption class="figure-caption">Figure X: RoBERTa 2 Sentiment Distribution per President</figcaption>
=======
<p><img src="index_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure X: RoBERTa 2 Sentiment Distribution per President</figcaption><p></p>
>>>>>>> cdd77dcf5cd537e2a21e0be11ffb9a3c9bda83db
</figure>
</div>
</div>
</div>
<p>Looking to the distribution of sentiments by presidents in figure XXX. De Klerk’s sentiment heavily leans towards the negative, with only a sparse presence of positive sentiment. Contrastingly, Mandela garners a majority of positive sentiments, although there’s a consistent representation across all sentiment spectrums, indicating diverse opinions. Mbeki’s sentiment profile is unique, spanning from negative through neutral to positive, with a pronounced peak in neutral sentiments. Motlanthe enjoys overwhelmingly positive feedback, with minimal divergences towards neutrality or negativity. In Zuma’s case, a dominant concentration of neutral sentiments emerges, bracketed by almost equal measures of positive and negative sentiments. Ramaphosa’s sentiment distribution is inclined towards positivity, but it doesn’t lack a substantial count of neutral mentions and a minor portion of negative sentiments.</p>
<div class="cell" data-execution_count="18">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<<<<<<< HEAD
<p><img src="index_files/figure-html/cell-19-output-1.png" width="662" height="457" class="figure-img"></p>
<figcaption class="figure-caption">Figure X: RoBERTa 2 Distribution of Sentiment Scores for each President</figcaption>
=======
<p><img src="index_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure X: RoBERTa 2 Distribution of Sentiment Scores for each President</figcaption><p></p>
>>>>>>> cdd77dcf5cd537e2a21e0be11ffb9a3c9bda83db
</figure>
</div>
</div>
</div>
<<<<<<< HEAD
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>m_lda_3 <span class="op">=</span> LdaModel.load(<span class="st">"topic_models/m_lda_3"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>m_lda_4 <span class="op">=</span> LdaModel.load(<span class="st">"topic_models/m_lda_4"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>m_lda_5 <span class="op">=</span> LdaModel.load(<span class="st">"topic_models/m_lda"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_topics(lda_model, m):</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    df<span class="op">=</span>pd.DataFrame({})</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    topics <span class="op">=</span> lda_model.print_topics(num_words<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, topic <span class="kw">in</span> <span class="bu">enumerate</span>(topics):</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        heading <span class="op">=</span> i<span class="op">+</span><span class="dv">1</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        content <span class="op">=</span> topic[<span class="dv">1</span>]</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        items <span class="op">=</span> content.split(<span class="st">' + '</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        tmp_df <span class="op">=</span> pd.DataFrame({<span class="ss">f'M</span><span class="sc">{</span>m<span class="sc">}</span><span class="ss"> Topic </span><span class="sc">{</span>heading<span class="sc">}</span><span class="ss">'</span>: [item.strip().replace(<span class="st">'"'</span>, <span class="st">''</span>).replace(<span class="st">'*'</span>, <span class="st">' | '</span>) <span class="cf">for</span> item <span class="kw">in</span> items]})</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> pd.concat([df,tmp_df],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>topics_df <span class="op">=</span> pd.concat([extract_topics(m_lda_3, <span class="dv">3</span>),extract_topics(m_lda_4, <span class="dv">4</span>),extract_topics(m_lda_5, <span class="dv">5</span>)], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>md_tbl <span class="op">=</span> topics_df.to_markdown(index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>md_tbl</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>'| M3 Topic 1          | M3 Topic 2          | M3 Topic 3         | M4 Topic 1         | M4 Topic 2             | M4 Topic 3       | M4 Topic 4          | M5 Topic 1         | M5 Topic 2         | M5 Topic 3             | M5 Topic 4          | M5 Topic 5          |\n|:--------------------|:--------------------|:-------------------|:-------------------|:-----------------------|:-----------------|:--------------------|:-------------------|:-------------------|:-----------------------|:--------------------|:--------------------|\n| 0.031 | south       | 0.020 | people      | 0.034 | year       | 0.045 | year       | 0.021 | new            | 0.029 | african  | 0.025 | work        | 0.057 | year       | 0.036 | people     | 0.032 | work           | 0.031 | country     | 0.055 | south       |\n| 0.016 | africa      | 0.018 | work        | 0.022 | african    | 0.041 | south      | 0.015 | also           | 0.027 | people   | 0.022 | national    | 0.037 | african    | 0.034 | government | 0.028 | africa         | 0.027 | new         | 0.022 | service     |\n| 0.015 | new         | 0.018 | country     | 0.020 | government | 0.026 | government | 0.014 | infrastructure | 0.024 | country  | 0.017 | public      | 0.024 | state      | 0.028 | national   | 0.022 | public         | 0.023 | business    | 0.020 | sector      |\n| 0.011 | also        | 0.014 | state       | 0.016 | national   | 0.017 | investment | 0.011 | ensure         | 0.022 | africa   | 0.016 | service     | 0.022 | economy    | 0.016 | nation     | 0.021 | last           | 0.021 | development | 0.016 | plan        |\n| 0.009 | together    | 0.012 | investment  | 0.013 | business   | 0.015 | economic   | 0.011 | million        | 0.019 | state    | 0.016 | development | 0.021 | investment | 0.014 | one        | 0.019 | economic       | 0.019 | need        | 0.014 | billion     |\n| 0.009 | must        | 0.012 | service     | 0.013 | economy    | 0.015 | need       | 0.011 | one            | 0.017 | business | 0.016 | last        | 0.018 | also       | 0.012 | project    | 0.017 | infrastructure | 0.018 | support     | 0.013 | water       |\n| 0.008 | billion     | 0.012 | development | 0.013 | public     | 0.014 | social     | 0.009 | many           | 0.017 | economy  | 0.013 | programme   | 0.018 | social     | 0.012 | community  | 0.015 | job            | 0.017 | together    | 0.011 | crisis      |\n| 0.008 | opportunity | 0.011 | sector      | 0.012 | last       | 0.014 | support    | 0.009 | life           | 0.015 | sector   | 0.011 | energy      | 0.016 | programme  | 0.011 | local      | 0.014 | ensure         | 0.013 | opportunity | 0.010 | employment  |\n| 0.007 | time        | 0.011 | economic    | 0.010 | social     | 0.013 | together   | 0.008 | local          | 0.012 | nation   | 0.011 | growth      | 0.014 | must       | 0.010 | provide    | 0.014 | energy         | 0.013 | time        | 0.009 | electricity |\n| 0.007 | community   | 0.011 | need        | 0.010 | support    | 0.012 | job        | 0.008 | first          | 0.011 | must     | 0.011 | billion     | 0.013 | growth     | 0.009 | action     | 0.014 | million        | 0.012 | many        | 0.009 | reform      |'</code></pre>
</div>
</div>
<p>The mean sentiment scores per president show President Mbeki exhibiting the highest mean sentiment score at approximately 1.65, suggesting a generally positive sentiment in his speeches. President Motlanthe followed closely with a mean sentiment score of approximately 1.44, indicating a similar trend of positively oriented speeches. In contrast, President de Klerk presented the lowest mean sentiment score, around 0.67, while Presidents Ramaphosa and Zuma demonstrated mean sentiment scores around 0.95 and 0.92, respectively.</p>
<div class="cell" data-execution_count="22">
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-23-output-1.png" width="662" height="471"></p>
</div>
</div>
<p>Figure X below shows that deKlerk is once again seen to possess less positive sentiments in his speeches than most of the other presidents, apart from Zuma, who has a very similar amount of positivity. Motlanthe and Mbeki are seen to have the greatest proportion of positive sentiments, while Zuma is seen to have the largest amount of neutral sentiments compared to the other presidents. As well as having the smallest proportion of positivity, deKlerk also has a large proportion of his sentences carrying negative sentiments.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># save object</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># sentiment_counts.reindex(adjusted_presidents_order).to_csv('wes_appendix/sentiment_counts.csv')</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>sentiment_counts <span class="op">=</span> pd.read_csv(<span class="st">"wes_appendix/sentiment_counts.csv"</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>sentiment_counts.plot(kind<span class="op">=</span><span class="st">'bar'</span>, stacked<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span>[colors[col] <span class="cf">for</span> col <span class="kw">in</span> sentiment_counts.columns <span class="cf">if</span> col <span class="op">!=</span> <span class="st">'Presidents'</span>])</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Sentiment Distribution per President'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Percentage'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'President'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">'Sentiment'</span>, fontsize<span class="op">=</span><span class="dv">20</span>, title_fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>) </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-25-output-1.png" width="675" height="487"></p>
</div>
</div>
<p>Figure Ax in the appendix shows the sentiments of each president over time. However, once again the extreme granularity of the plots makes it difficult to extract any useful information. Noticeably however, deKlerk’s strong negative sentiments are apparent from such a broad scoped view.</p>
<p>The histograms below show the sentiment score distribution for the presidents. All histograms appear to be slightly skewed to the left, indicating a high frequency of positive sentiment. Mandela appears to have the most evenly spread sentiment distribution, with the fewest number of protruding bars, while de Klerk mainly has a uniform sentiment distribution, with a notable deviation from that occuring in the neutral sentiment territory. Ramaphosa’s, Mbeki’s and Zuma’s sentiment distributions are both centered on the positive side of zero, indicating a generally positive sentiment, while Motlanthe’s most common sentiment is actually slightly negative, however that is offset by the high frequency of positive sentiments.</p>
<div class="cell" data-execution_count="25">
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-26-output-1.png" width="704" height="476"></p>
=======
<div class="cell" data-execution_count="22">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure X: Topic Weights and Terms Table</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The mean sentiment scores per president show President Mbeki exhibiting the highest mean sentiment score at approximately 1.65, suggesting a generally positive sentiment in his speeches. President Motlanthe followed closely with a mean sentiment score of approximately 1.44, indicating a similar trend of positively oriented speeches. In contrast, President de Klerk presented the lowest mean sentiment score, around 0.67, while Presidents Ramaphosa and Zuma demonstrated mean sentiment scores around 0.95 and 0.92, respectively.</p>
<div class="cell" data-execution_count="24">
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Figure X below shows that deKlerk is once again seen to possess less positive sentiments in his speeches than most of the other presidents, apart from Zuma, who has a very similar amount of positivity. Motlanthe and Mbeki are seen to have the greatest proportion of positive sentiments, while Zuma is seen to have the largest amount of neutral sentiments compared to the other presidents. As well as having the smallest proportion of positivity, deKlerk also has a large proportion of his sentences carrying negative sentiments.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># save object</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># sentiment_counts.reindex(adjusted_presidents_order).to_csv('wes_appendix/sentiment_counts.csv')</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>sentiment_counts <span class="op">=</span> pd.read_csv(<span class="st">"wes_appendix/sentiment_counts.csv"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>sentiment_counts.plot(kind<span class="op">=</span><span class="st">'bar'</span>, stacked<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span>[colors[col] <span class="cf">for</span> col <span class="kw">in</span> sentiment_counts.columns <span class="cf">if</span> col <span class="op">!=</span> <span class="st">'Presidents'</span>])</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Sentiment Distribution per President'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Percentage'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'President'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">'Sentiment'</span>, fontsize<span class="op">=</span><span class="dv">20</span>, title_fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>) </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-27-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Figure Ax in the appendix shows the sentiments of each president over time. However, once again the extreme granularity of the plots makes it difficult to extract any useful information. Noticeably however, deKlerk’s strong negative sentiments are apparent from such a broad scoped view.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.colors <span class="im">import</span> LinearSegmentedColormap</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> cm</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> cm</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_for_president_gradient(president, df):</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter dataframe for the selected president</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    president_df <span class="op">=</span> df[df[<span class="st">'Presidents'</span>] <span class="op">==</span> president]</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sorting data by order (using the 'Unnamed: 0' column as the order)</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    president_df <span class="op">=</span> president_df.sort_values(by<span class="op">=</span><span class="st">'Unnamed: 0'</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize the scores to [0,1] for colormap</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    norm <span class="op">=</span> plt.Normalize(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Custom colormap: Red -&gt; Gray -&gt; Blue</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    custom_cmap <span class="op">=</span> LinearSegmentedColormap.from_list(<span class="st">"custom"</span>, [<span class="st">"red"</span>, <span class="st">"gray"</span>, <span class="st">"blue"</span>])</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plotting with a black background and custom colormap</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    bars <span class="op">=</span> ax.bar(np.arange(<span class="bu">len</span>(president_df)), president_df[<span class="st">'Sentiment_Score'</span>], </span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>                  color<span class="op">=</span>custom_cmap(norm(president_df[<span class="st">'Sentiment_Score'</span>])), width<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'Sentiment Score over time for President </span><span class="sc">{</span>president<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'Order of Sentences'</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Sentiment Intensity'</span>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    ax.axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'white'</span>,linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>    ax.grid(axis<span class="op">=</span><span class="st">'y'</span>, color<span class="op">=</span><span class="st">'white'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    ax.set_facecolor(<span class="st">'black'</span>)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    fig.colorbar(cm.ScalarMappable(norm<span class="op">=</span>norm, cmap<span class="op">=</span>custom_cmap), ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">'Sentiment Score'</span>)</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>presidents_list <span class="op">=</span> afn_df[<span class="st">'Presidents'</span>].unique()</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_in_grid(president, ax):</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Plot sentiment scores for a given president on a given axes."""</span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>    president_df <span class="op">=</span> afn_df[afn_df[<span class="st">'Presidents'</span>] <span class="op">==</span> president]</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">#president_df = president_df.sort_values(by='Unnamed: 0')</span></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize the scores for colormap</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    norm <span class="op">=</span> plt.Normalize(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    custom_cmap <span class="op">=</span> LinearSegmentedColormap.from_list(<span class="st">"custom"</span>, [<span class="st">"red"</span>, <span class="st">"gray"</span>, <span class="st">"blue"</span>])</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>    bars <span class="op">=</span> ax.bar(np.arange(<span class="bu">len</span>(president_df)), president_df[<span class="st">'scores'</span>], </span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>                  color<span class="op">=</span>custom_cmap(norm(president_df[<span class="st">'scores'</span>])), width<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'</span><span class="sc">{</span>president<span class="sc">}</span><span class="ss">'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>    ax.axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>    ax.grid(axis<span class="op">=</span><span class="st">'y'</span>, color<span class="op">=</span><span class="st">'white'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>    ax.set_facecolor(<span class="st">'black'</span>)</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating a 2x3 grid plot for all presidents</span></span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">'Sentiment Scores over time for each President'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> president, ax <span class="kw">in</span> <span class="bu">zip</span>(adjusted_presidents_order, axes.ravel()):</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>    plot_in_grid(president, ax)</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust layout</span></span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(top<span class="op">=</span><span class="fl">0.90</span>)</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes.ravel():</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>    ax.tick_params(axis<span class="op">=</span><span class="st">'x'</span>, labelrotation<span class="op">=</span><span class="dv">45</span>, labelsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>    ax.tick_params(axis<span class="op">=</span><span class="st">'y'</span>, labelsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Set x and y labels fontsize</span></span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes[<span class="dv">1</span>, :]:</span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'Sentences'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes[:, <span class="dv">0</span>]:</span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Scores'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-28-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The histograms below show the sentiment score distribution for the presidents. All histograms appear to be slightly skewed to the left, indicating a high frequency of positive sentiment. Mandela appears to have the most evenly spread sentiment distribution, with the fewest number of protruding bars, while de Klerk mainly has a uniform sentiment distribution, with a notable deviation from that occuring in the neutral sentiment territory. Ramaphosa’s, Mbeki’s and Zuma’s sentiment distributions are both centered on the positive side of zero, indicating a generally positive sentiment, while Motlanthe’s most common sentiment is actually slightly negative, however that is offset by the high frequency of positive sentiments.</p>
<div class="cell" data-execution_count="28">
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-29-output-1.png" class="img-fluid"></p>
>>>>>>> cdd77dcf5cd537e2a21e0be11ffb9a3c9bda83db
</div>
</div>
<section id="nrc" class="level3">
<h3 class="anchored" data-anchor-id="nrc">NRC</h3>
<p>Using the NRC emotion lexicon we see that all presidents have their most common sentiment being positive, while the particular emotions in there sentences differ. A common emotion amongst all presidents is trust. Anticipation is a frequently evoked emotion from the presidents, besides for deKlerk. Other relatively common emotions include fear and joy.</p>
</section>
</section>
<section id="latent-dirichlet-allocation-1" class="level2">
<h2 class="anchored" data-anchor-id="latent-dirichlet-allocation-1">Latent Dirichlet Allocation</h2>
<p>The ALL models were trained on the corpus of all thirty-six speeches, iteratively decreasing the number of topics from five until three. At five topics, two of the topics are almost overlaid - indicating that they are closely linked and probably contain a single topic. At four topics, one of the topics sits almost on the origin of the latent variables. This suggests that this ‘topic’ does not have differentiating features and likely consists of neutral words, for example it contains ‘new’, ‘also’, and a set of numbers, ‘one’, ‘two’, ‘million’. The third model, with three topics, has three clearly differentiated topics sitting at the extremes of the latent variables axes. Three-topics models were then trained for each of the presidents, using only their respective speeches as the corpus. We gave the top ten words from each topic for each presidents’ model and for the three-topic ALL model to ChatGPT to see if it could discern the nature of the topics identified by the LDA models. ChatGPT does a good job of drawing topic titles from the model output, but the further descriptions are hit and miss. The output from ChatGPT is as follows:</p>
<p>LDA-Ramaphosa:</p>
<ul>
<li>Topic 1: People and societal needs - this topic includes words related to the needs of the people and society. This could be associated with President Ramaphosa’s focus on addressing the needs of the South African population, which could include policies related to social welfare and community development.
<ul>
<li>Examples: “people,” “need,” “african”.</li>
</ul></li>
<li>Topic 2: Economic development and business - President Ramaphosa is known for promoting economic development and business growth in South Africa. This topic contains words related to business and economic sectors.
<ul>
<li>Examples: “business,” “government,” “economic”.</li>
</ul></li>
<li>Topic 3: Time and work commitment - this topic contains words related to time and work commitment, possibly reflecting President Ramaphosa’s commitment to his role and responsibilities as a leader.
<ul>
<li>Examples: “year,” “work,” “must”.</li>
</ul></li>
</ul>
<p>LDA-Zuma:</p>
<ul>
<li>Topic 1: South Africa and government - this topic includes words related to South Africa and government. President Zuma’s tenure was marked by various political and governmental issues, making this a prominent topic.
<ul>
<li>Examples: “south,” “government,” “africa”</li>
</ul></li>
<li>Topic 2: Economic sectors and development - President Zuma’s administration likely involved policies and discussions related to economic sectors and development, as indicated by the words in this topic.
<ul>
<li>Examples: “sector,” “new,” “economic”</li>
</ul></li>
<li>Topic 3: Time and population - this topic may be associated with President Zuma’s time in office and concerns related to the South African population.
<ul>
<li>Examples: “year,” “country,” “million”</li>
</ul></li>
</ul>
<p>LDA-Mandela:</p>
<ul>
<li>Topic 1: Public affairs and the country - this topic encompasses words associated with public affairs and the country. Given Nelson Mandela’s role as South Africa’s first post-apartheid president, it’s likely that topics related to the nation were significant.
<ul>
<li>Examples: “public,” “country,” “african”</li>
</ul></li>
<li>Topic 2: Government work and public service - President Mandela’s government focused on public service and the work required to build a new South Africa.
<ul>
<li>Examples: “government,” “work,” “service”</li>
</ul></li>
<li>Topic 3: Time and commitment - Words related to time and commitment reflect Mandela’s dedication to the country and his work.
<ul>
<li>Example: “year,” “must,” “national”</li>
</ul></li>
</ul>
<p>LDA-deKlerk:</p>
<ul>
<li>Topic 1: Political alliance and elections - this topic includes words related to political alliances and elections. President de Klerk played a crucial role in the transition from apartheid to democracy.
<ul>
<li>Examples: “alliance,” “election,” “african”</li>
</ul></li>
<li>Topic 2: Constitution and political parties - given his role in the negotiation of South Africa’s new constitution, this topic reflects words related to the constitution and political parties.
<ul>
<li>Examples: “constitution,” “party,” “power”</li>
</ul></li>
<li>Topic 3: South African provinces and constitutional concerns - the words in this topic may relate to the various provinces in South Africa and constitutional concerns that were addressed during his leadership.
<ul>
<li>Examples: “south,” “province,” “constitutional”</li>
</ul></li>
</ul>
<p>LDA-Mbeki:</p>
<ul>
<li>Topic 1: Time and government programs - this topic could be associated with President Mbeki’s focus on time-bound government programs and initiatives.
<ul>
<li>Examples: “year,” “programme,” “government”</li>
</ul></li>
<li>Topic 2: National issues and the country - this topic encompasses words related to national issues and the country, reflecting his leadership during a period of significant national importance.
<ul>
<li>Examples: “country,” “national,” “work”</li>
</ul></li>
<li>Topic 3: Economic sectors and government efforts - President Mbeki’s administration focused on economic sectors and government efforts, as indicated by the words in this topic.
<ul>
<li>Examples: “sector,” “effort,” “government”</li>
</ul></li>
</ul>
<p>LDA-Motlanthe:</p>
<ul>
<li>Topic 1 - South Africa and African development - this topic includes words related to South Africa and African development, reflecting a focus on regional and national development.
<ul>
<li>Examples: “south,” “african,” “development”</li>
</ul></li>
<li>Topic 2: Government work and public sector - this topic likely represents the emphasis on government work and the public sector during President Motlanthe’s leadership.
<ul>
<li>Examples: “government,” “sector,” “regard”</li>
</ul></li>
<li>Topic 3: Economic development and work - words related to economic development and work suggest a focus on economic policies and employment during his tenure.
<ul>
<li>Examples: “economic,” “work,” “growth”</li>
</ul></li>
</ul>
<p>LDA-All:</p>
<ul>
<li>Topic 1: South Africa and African development - this topic emphasizes South Africa and its development, which is a broad, overarching theme applicable to all six Presidents.
<ul>
<li>Examples: “south,” “africa,” “new”</li>
</ul></li>
<li>Topic 2: People, work, and service - this topic encompasses words related to the people, their work, and the services provided, reflecting the importance of public service and commitment.
<ul>
<li>Examples: “people,” “work,” “service”</li>
</ul></li>
<li>Topic 3 - Time and government - the words in this topic are related to time, government, and national affairs, indicating a focus on governance and the passage of time across all Presidential terms.
<ul>
<li>Examples: “year,” “african,” “government”</li>
</ul></li>
</ul>
<section id="probablistic-latent-semantic-analysis-1" class="level3">
<h3 class="anchored" data-anchor-id="probablistic-latent-semantic-analysis-1">Probablistic Latent Semantic Analysis</h3>
<<<<<<< HEAD
<p>pLSA models are very sensitive to data sparsity, the document-term matrix has only around a third of its cells populated. The model struggles to capture meaningful relationships through its dimensionality reduction techniques in the sparse data.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> LdaModel, LsiModel</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim <span class="im">import</span> corpora</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>m_pLSA_4 <span class="op">=</span> LsiModel.load(<span class="st">"topic_models/m_pLSA_4"</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>num_words<span class="op">=</span><span class="dv">20</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>topics <span class="op">=</span> m_pLSA_4.print_topics(num_topics<span class="op">=</span><span class="dv">4</span>, num_words<span class="op">=</span>num_words)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>df4<span class="op">=</span>pd.DataFrame({})</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> topic <span class="kw">in</span> topics:</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    content <span class="op">=</span> topic[<span class="dv">1</span>]</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    words<span class="op">=</span>[]</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    scores<span class="op">=</span>[]</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    scorewords <span class="op">=</span> content.split(<span class="st">' + '</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> scorewords:</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        spl<span class="op">=</span>item.split(<span class="st">'*'</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        scores.append(spl[<span class="dv">0</span>])</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        words.append(spl[<span class="dv">1</span>].replace(<span class="st">'"'</span>,<span class="st">''</span>))</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    topic_df<span class="op">=</span>pd.DataFrame({<span class="ss">f'T</span><span class="sc">{</span>topic[<span class="dv">0</span>]<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Words'</span>: words, <span class="ss">f'T</span><span class="sc">{</span>topic[<span class="dv">0</span>]<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Scores'</span>: scores})</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    df4 <span class="op">=</span> pd.concat([df4, topic_df], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 2x2 grid of subplots</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> [<span class="dv">0</span>,<span class="dv">1</span>]:</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> [<span class="dv">0</span>,<span class="dv">1</span>]:</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        t<span class="op">=</span><span class="dv">2</span><span class="op">*</span>i<span class="op">+</span>j<span class="op">+</span><span class="dv">1</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        axs[i, j].barh(df4[<span class="ss">f'T</span><span class="sc">{</span>t<span class="sc">}</span><span class="ss"> Words'</span>], df4[<span class="ss">f'T</span><span class="sc">{</span>t<span class="sc">}</span><span class="ss"> Scores'</span>])</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        axs[i, j].set_xlabel(<span class="st">'Words'</span>)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        axs[i, j].set_ylabel(<span class="st">'Weight'</span>)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>        axs[i, j].set_title(<span class="ss">f'M4: Topic </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        axs[i, j].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">90</span>, labelsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        axs[i, j].tick_params(axis<span class="op">=</span><span class="st">'y'</span>, rotation<span class="op">=</span><span class="dv">0</span>, labelsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-28-output-1.png" width="662" height="470"></p>
=======
<p>The weights produced for each word in the topics of the pLSA models are not very evenly distributed. This suggests that there may have be numerical difficulties in the computation during model training. pLSA models are very sensitive to data sparsity, the document-term matrix has only around a third of its cells populated. The model struggles to capture meaningful relationships through its dimensionality reduction techniques in the sparse data.</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> LdaModel, LsiModel</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim <span class="im">import</span> corpora</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>m_pLSA_4 <span class="op">=</span> LsiModel.load(<span class="st">"topic_models/m_pLSA_4"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>num_words<span class="op">=</span><span class="dv">20</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>topics <span class="op">=</span> m_pLSA_4.print_topics(num_topics<span class="op">=</span><span class="dv">4</span>, num_words<span class="op">=</span>num_words)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>df4<span class="op">=</span>pd.DataFrame({})</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> topic <span class="kw">in</span> topics:</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    content <span class="op">=</span> topic[<span class="dv">1</span>]</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    words<span class="op">=</span>[]</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    scores<span class="op">=</span>[]</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    scorewords <span class="op">=</span> content.split(<span class="st">' + '</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> scorewords:</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        spl<span class="op">=</span>item.split(<span class="st">'*'</span>)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        scores.append(spl[<span class="dv">0</span>])</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        words.append(spl[<span class="dv">1</span>].replace(<span class="st">'"'</span>,<span class="st">''</span>))</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    topic_df<span class="op">=</span>pd.DataFrame({<span class="ss">f'T</span><span class="sc">{</span>topic[<span class="dv">0</span>]<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Words'</span>: words, <span class="ss">f'T</span><span class="sc">{</span>topic[<span class="dv">0</span>]<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Scores'</span>: scores})</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    df4 <span class="op">=</span> pd.concat([df4, topic_df], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 2x2 grid of subplots</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> [<span class="dv">0</span>,<span class="dv">1</span>]:</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> [<span class="dv">0</span>,<span class="dv">1</span>]:</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>        t<span class="op">=</span><span class="dv">2</span><span class="op">*</span>i<span class="op">+</span>j<span class="op">+</span><span class="dv">1</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>        axs[i, j].barh(df4[<span class="ss">f'T</span><span class="sc">{</span>t<span class="sc">}</span><span class="ss"> Words'</span>], df4[<span class="ss">f'T</span><span class="sc">{</span>t<span class="sc">}</span><span class="ss"> Scores'</span>])</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>        axs[i, j].set_xlabel(<span class="st">'Words'</span>)</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>        axs[i, j].set_ylabel(<span class="st">'Weight'</span>)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>        axs[i, j].set_title(<span class="ss">f'M4: Topic </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>        axs[i, j].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">90</span>, labelsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>        axs[i, j].tick_params(axis<span class="op">=</span><span class="st">'y'</span>, rotation<span class="op">=</span><span class="dv">0</span>, labelsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
>>>>>>> cdd77dcf5cd537e2a21e0be11ffb9a3c9bda83db
</div>
</div>
</section>
</section>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<p>The State of the Nation Address (SONA) gives an annual comprehensive overview of the nation’s progress, challenges, and future prospects. Through the application of Natural Language Processing (NLP), specifically sentiment analysis and topic modelling, this study has endeavoured to extract insights from these speeches to present a holistic, data-driven portrayal of the South African political landscape over three decades.</p>
<p>Using the RoBERTa, NRC, and Afinn models, the analysis provides a layered perspective of the country’s political sentiment. RoBERTa’s findings indicate that most presidents, from Mandela to Ramaphosa, conveyed an overall positive sentiment. The NRC model captured a spectrum of emotions, from trust and anticipation during Mandela’s tenure to fear and surprise in Zuma’s era. Afinn results largely corroborated with RoBERTa, strengthening the overall sentiment conclusions. Mandela’s emphasis on societal unity and nation-building post-apartheid possibly fueled the positive sentiments. This trend continued with Mbeki, with an undercurrent of hope and trust. Zuma’s era, intriguingly, maintained a high positive sentiment despite palpable emotions of fear and surprise, indicating a divergence between optimistic rhetoric and grounded realities. Ramaphosa’s sentiments, while positive, were more subdued, reflecting challenges like the COVID-19 pandemic. In stark contrast, de Klerk’s tenure, as seen particularly in the NRC results, showed heightened emotions of sadness and fear, mirroring the transitional period around apartheid’s end.</p>
<p>The LDA model effectively identified core themes across the terms. Mandela emphasized nation-building and unity. De Klerk, in contrast, focused on political alliances, reforms, and apartheid’s complexities. Mbeki’s speeches indicated shifts towards economic sectors and development. Motlanthe highlighted South Africa’s broader African context, and Zuma balanced national and economic themes. However, Probabilistic Latent Semantic Analysis (pLSA) had challenges, emphasizing the importance of data quality and quantity for NLP projects.</p>
</section>
<section id="limitations-and-recommendations" class="level1">
<h1>Limitations and Recommendations</h1>
<p>While insightful, the study has limitations. Sentiment analysis can sometimes simplify complex rhetoric into basic sentiments, risking nuanced emotion loss. Relying on RoBERTa, while robust, could be complemented by other models for a rounded analysis. True class sentiment labels would allow rigorous model performance interrogation. Topic modelling, being interpretive, lacks quantifiable validation methods. Labelled data can facilitate model performance assessment.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The NLP-based SONA speech analysis paints a multifaceted South African political journey narrative. As sentiments evolved and topics transitioned, they narrated a nation grappling with its past, shaping its present, and envisioning its future. With advancing NLP methodologies, such analyses will be pivotal in decoding global political and societal narratives.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>