---
title: "ChatGPT"
format: html
---

ChatGPT had mixed results. On the one hand for a preliminary literature review it provided useful results of methods, though in showing actual refernces ChatGPT often halunicated refernces or misused nebulus references to make true but specific points not found in the references. Another plan we tried was to use chatGPT to try and make true class labels for sentiments of sentences. In small batches this worked well, but across the entire dataset we found it classed almost all sentences in neutral, procing chatGPT strugled to discern the detailed linguistic semantics of the political speeches.

A useful application was topic modelling. As shown in the main body using it to try and interpret the topic model groups proved to be more fruitful as it was able to extract interpretability otherwise difficult to do for humans. Finally general troubleshooting for code syntax 